{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f789791",
   "metadata": {},
   "source": [
    "[PyTorch Toutrials](https://learnopencv.com/getting-started-with-pytorch/)\n",
    "\n",
    "![alt text](c3_w1_pytorch_basics_cover.jpg)\n",
    "\n",
    "\n",
    "Table of Contents\n",
    "1. Converting Image to tensors\n",
    "\n",
    "2. Introduction to Tensors and its Operations\n",
    "\n",
    "3. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if you have conda installed\n",
    "# !conda install -c pytorch pytorch\n",
    "\n",
    "# Use this if you are on Google Colab or don't have conda installed\n",
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12cad28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "urls = [\n",
    "    (\"https://learnopencv.com/wp-content/uploads/2024/07/mnist_0.jpg\", \"mnist_0.jpg\"),\n",
    "    (\"https://learnopencv.com/wp-content/uploads/2024/07/mnist_1.jpg\", \"mnist_1.jpg\")\n",
    "]\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "for url, filename in urls:\n",
    "    r = requests.get(url, headers=headers)\n",
    "    if r.status_code == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "    else:\n",
    "        print(f\"Failed to download {url}, status code: {r.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download some digit images from MNIST dataset (Google Colab)\n",
    "# !wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_0.jpg\" -O \"mnist_0.jpg\"\n",
    "# !wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_1.jpg\" -O \"mnist_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63c1a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mr\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe7fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install --upgrade --force-reinstall opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1bff239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee05576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version : 2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version : {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e599b24",
   "metadata": {},
   "source": [
    "### 1. *`Converting Images to Batched tensors`*\n",
    "\n",
    "- Image is made up of pixel arrays that represent the intensity of pixels in grayscale or the color values in RGB format.\n",
    "- When working with deep learning models, it's often necessary to convert these images into tensors, which are the `primary data structures used in PyTorch for handling and processing data`.\n",
    "\n",
    "- Tensors: `multi-dimensional arrays similar to NumPy arrays, but with additional capabilities for GPU acceleration and automatic differentiation`. \n",
    "- Tensors are the `fundamental building blocks for representing data and parameters in neural networks`.\n",
    "\n",
    "- Batches: Batching is a technique where `multiple data samples (images, in this case) are grouped together into a single tensor`. \n",
    "\n",
    "- This allows efficient processing of multiple samples simultaneously, to take advantage of the `parallel processing `capabilities of modern hardware.\n",
    "\n",
    "- In the following block, we will see an example of `converting two MNIST images` into a `single batched tensor of shape [2,3,28,28]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08d2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_0_array_og = cv2.imread(\"mnist_0.jpg\")\n",
    "digit_1_array_og = cv2.imread(\"mnist_1.jpg\")\n",
    "\n",
    "digit_0_array_gray = cv2.imread(\"mnist_0.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "digit_1_array_gray = cv2.imread(\"mnist_1.jpg\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b737302f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the images\n",
    "fig, ax = plt.subplots(1, 2, figsize=[10, 5])\n",
    "\n",
    "ax[0].imshow(digit_0_array_og, cmap='gray', interpolation='none')\n",
    "ax[0].set_title(\"Digit 0 Image\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(digit_1_array_og, cmap='gray', interpolation='none')\n",
    "ax[1].set_title(\"Digit 1 Image\")\n",
    "ax[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ddd79e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the images\n",
    "fig, ax = plt.subplots(1, 2, figsize=[10, 5])\n",
    "\n",
    "ax[0].imshow(digit_0_array_gray, cmap='gray', interpolation='none')\n",
    "ax[0].set_title(\"Digit 0 Image\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(digit_1_array_gray, cmap='gray', interpolation='none')\n",
    "ax[1].set_title(\"Digit 1 Image\")\n",
    "ax[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73daafb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Array Shape = (28, 28, 3)\n",
      "Min. Pixel Value = 0\n",
      "Max. Pixel Value = 255\n"
     ]
    }
   ],
   "source": [
    "# Numpy array with three channels\n",
    "print(f\"Image Array Shape = {digit_0_array_og.shape}\")\n",
    "\n",
    "print(f\"Min. Pixel Value = {np.min(digit_0_array_og)}\")\n",
    "print(f\"Max. Pixel Value = {np.max(digit_0_array_og)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd90782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
       "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
       "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
       "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
       "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
       "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
       "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
       "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
       "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
       "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
       "          1,   5],\n",
       "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
       "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
       "          0,   4],\n",
       "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
       "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
       "          0,   3],\n",
       "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
       "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
       "          0,   2],\n",
       "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
       "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
       "          0,   2],\n",
       "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
       "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
       "          0,   3],\n",
       "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
       "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
       "          0,   5],\n",
       "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
       "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
       "          0,   6],\n",
       "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
       "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
       "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
       "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
       "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
       "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
       "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
       "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
       "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will have a look at 28x28 single channel image's pixel values\n",
    "digit_0_array_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d4cc8",
   "metadata": {},
   "source": [
    "#### *`1.1. Convert Numpy array to Torch tensors`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91f39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the images to PyTorch tensors and normalize\n",
    "# troch.tensor(___, dtype=)\n",
    "# normalize -> means pixel values that are of range (0 -> 255) will be of range(0 -> 1)\n",
    "\n",
    "img_tensor_0 = torch.tensor(digit_0_array_og, dtype=torch.float32) / 255.0\n",
    "img_tensor_1 = torch.tensor(digit_1_array_og, dtype=torch.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30183594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Normalized Digit 0 Tensor = torch.Size([28, 28, 3])\n",
      "Shape of Normalized Digit 1 Tensor = torch.Size([28, 28, 3])\n",
      "Normalized Min. Pixel Value = 0.0\n",
      "Normalized Max. Pixel Value = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Normalized Digit 0 Tensor = {img_tensor_0.shape}\")\n",
    "print(f\"Shape of Normalized Digit 1 Tensor = {img_tensor_1.shape}\")\n",
    "\n",
    "print(f\"Normalized Min. Pixel Value = {torch.min(img_tensor_0)}\")\n",
    "print(f\"Normalized Max. Pixel Value = {torch.max(img_tensor_0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf07d7d3",
   "metadata": {},
   "source": [
    "- The Shape is the Same\n",
    "- But, the range of normalized image is changed to be from 0 to 1 with floating point numbers in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34afaf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_tensor_0, cmap='gray')\n",
    "plt.title(\"Normalized Digit 0 Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c724704",
   "metadata": {},
   "source": [
    "#### *`1.2. Creating Input Batch`*\n",
    "- From 2 Images (Tensors) -> Create 1 Batch (Group of Tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f0822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Shape = torch.Size([2, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "batch_tensor = torch.stack([img_tensor_0, img_tensor_1])\n",
    "\n",
    "# In PyTorch the forward pass of input images to the model is expected to have a batch_size > 1\n",
    "print(f\"Batch Tensor Shape = {batch_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b60105",
   "metadata": {},
   "source": [
    "- Consist of `2 Tensors and each tensor's shape of [28, 28, 3] `\n",
    "\n",
    "- Note: `Additionally in PyTorch, image tensors typically follow the shape convention [N ,C ,H ,W] unlike tensorflow which follows [N, H, W, C].`\n",
    "\n",
    "- Therefore, we need to bring the `color channel to the second dimension`. This can be achieved using either torch.view() or torch.permute()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42686d",
   "metadata": {},
   "source": [
    "- Values:-\n",
    "[2, 28, 28, 3]  ---> [2, 3, 28, 28]\n",
    "- Indices:-\n",
    "[0, 1,  2,  3]  ---> [0, 3,  1,  2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ef12daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Shape = torch.Size([2, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# [N, C, H, W]\n",
    "batch_input = batch_tensor.permute(0, 3, 1, 2)\n",
    "print(f\"Batch Tensor Shape = {batch_input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d63c36e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Tensor Shape = torch.Size([2, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# [N, C, H, W]\n",
    "batch_input = batch_tensor.view(2, 3, 28, 28)\n",
    "print(f\"Batch Tensor Shape = {batch_input.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f992a364",
   "metadata": {},
   "source": [
    "### 2.*`Introduction to Tensors and its Operations`*\n",
    "- Tensor is simply a fancy name given to matrices. \n",
    "- If you are familiar with NumPy arrays, understanding and using PyTorch Tensors will be very easy. \n",
    "- A scalar value is represented by a 0-dimensional Tensor\n",
    "- Similarly, a column/row matrix is represented using a 1-D Tensor and so on.\n",
    "![alt text](PyTorch-Tensors.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f37e6",
   "metadata": {},
   "source": [
    "#### *`2.1. Construct your first Tensor`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cbeb2",
   "metadata": {},
   "source": [
    "- Create a Tensor with just ones in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ca83aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = torch.ones((2, 3))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cd9764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# You can change the Datatype of Elements\n",
    "a = torch.ones(5, dtype=torch.int32)\n",
    "b = torch.ones((2, 3), dtype=torch.int64)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10493732",
   "metadata": {},
   "source": [
    "- Create a Tensor with just zeros in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0007d3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(5)\n",
    "b = torch.zeros((5, 4))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a69db",
   "metadata": {},
   "source": [
    "- We can similarly create Tensor with custom values as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10c2c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000,  2.5000,  3.1400, 12.0000])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Tensor of 1 Dimension == Vector\n",
    "t = torch.tensor([1, 2.5, 3.14, 12])\n",
    "print(t)\n",
    "\n",
    "print(t.shape)\n",
    "print(t.size())\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26f7c8",
   "metadata": {},
   "source": [
    "- Now, lets create some tensors of higher dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77833825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix == Tensor of 2 Dimensions\n",
    "f = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bbd1028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Tensor of 3 Dimensions\n",
    "f = torch.tensor([[\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6]\n",
    "    ]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "print(f)\n",
    "print(f.shape)\n",
    "print(f.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd24bc",
   "metadata": {},
   "source": [
    "- Creates a tensor of size `size` filled with `fill_value`. \n",
    "- The tensor's dtype is inferred from fill_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0b4fba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([5, 5, 5])\n",
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 2D Tensor\n",
    "a = torch.full(size=(2, 3), fill_value=2.0)\n",
    "\n",
    "# 1D Tensor\n",
    "b = torch.full((3, ), 5)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "print(a.dtype)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbfb3b",
   "metadata": {},
   "source": [
    "#### *`2.2. Access an element in Tensor`*\n",
    "- All indices starting from 0\n",
    "- We can use Positive Indexing (0, 1, 2, ....) \n",
    "- and Negative Indexing (..., -3, -2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b433da30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  2.5000,  3.1400, 12.0000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Tensor aka Vector -> [_]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2ff8dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1400)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get element at index 2\n",
    "t[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d1c36",
   "metadata": {},
   "source": [
    "- To access one particular element in a tensor, we will need to specify indices equal to the dimension of the tensor.\n",
    "- Thats why for 1D-tensor we only had to specify one index.\n",
    "- Thats why for 2D-tensor we only had to specify two indices.\n",
    "- Thats why for 3D-tensor we only had to specify three indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d47e2993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D Tensor Access -> [_][_]\n",
    "a = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0]\n",
    "])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d41f744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "# All Elements\n",
    "print(f[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bfa0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access First Row\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c442fdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access Second Row\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0318d144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access First column\n",
    "a[0:2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff9dcb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 5.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access Second column\n",
    "a[0:2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69d00fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get element at row 1, column 0\n",
    "# a[1, 0]\n",
    "# a[1][0]\n",
    "\n",
    "a[1][0] == a[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2de70477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# All elements from index 1 to 2 (excluding element 3)\n",
    "print(a[1:3])\n",
    "\n",
    "# All elements till index 4 (exclusive)\n",
    "print(a[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a37442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D Tensor Access -> [_][_][_]\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39f221ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "# All Elements\n",
    "print(f[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ddaf441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly for 3D Tensor\n",
    "f[1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9dbaf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b271809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[1, 0, 0] == f[1][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b9a5b",
   "metadata": {},
   "source": [
    "#### *`2.3. Specify data type of elements`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5a4d3",
   "metadata": {},
   "source": [
    "- Whenever we create a tensor, PyTorch decides the data type of the elements of the tensor such that the data type can cover all the elements of the tensor.\n",
    "- We can override this by specifying the data type while creating the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3f5d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "int_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(int_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84164e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# What if we changed any one element to floating point number?\n",
    "int_tensor = torch.tensor([[1, 2, 3], [4.0, 5, 6]])\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d99b731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# This can be overridden as follows\n",
    "float_tensor = torch.tensor([[1, 2, 3], [4.0, 5, 6]])\n",
    "int_tensor = float_tensor.type(torch.int64)\n",
    "\n",
    "print(int_tensor.dtype)\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644bbc31",
   "metadata": {},
   "source": [
    "#### *`2.4. Tensor to/from NumPy Array`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0f844e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2., 3.],\n",
       "        [4., 5., 6.]],\n",
       "\n",
       "       [[1., 2., 3.],\n",
       "        [4., 5., 6.]]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Array\n",
    "f_np = f.numpy()\n",
    "\n",
    "f_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3796469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array to Tensor\n",
    "f = torch.from_numpy(f_np)\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46f03c",
   "metadata": {},
   "source": [
    "#### *`2.5. Arithmetic Operations on Tensors`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3da438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[-1,  2, -3],\n",
      "        [ 4, -5,  6]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor\n",
    "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor2 = torch.tensor([[-1, 2, -3], [4, -5, 6]])\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce65369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  4,  0],\n",
      "        [ 8,  0, 12]])\n",
      "tensor([[ 0,  4,  0],\n",
      "        [ 8,  0, 12]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "print(tensor1 + tensor2)\n",
    "\n",
    "print(torch.add(tensor1, tensor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99e90d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  0,  6],\n",
      "        [ 0, 10,  0]])\n",
      "tensor([[ 2,  0,  6],\n",
      "        [ 0, 10,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Subtraction\n",
    "print(tensor1 - tensor2)\n",
    "\n",
    "print(torch.subtract(tensor1, tensor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8de76e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12]])\n",
      "tensor([[ 5, 10, 15],\n",
      "        [20, 25, 30]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Multiplication ---->> Tensor with Scalar\n",
    "print(tensor1 * 2)\n",
    "\n",
    "print(tensor1 * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61a168f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1,   4,  -9],\n",
      "        [ 16, -25,  36]])\n"
     ]
    }
   ],
   "source": [
    "# 2. Tensor with another tensor ---->> Elementwise Multiplication\n",
    "print(tensor1 * tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "774463d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n",
      "--------------------\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 7]])\n",
      "Tensor1 * Tensor3 = \n",
      "--------------------\n",
      "tensor([[22, 31],\n",
      "        [49, 70]])\n"
     ]
    }
   ],
   "source": [
    "# 3. Matrix multiplication ---->> T1(N, M) * T2(M, C)\n",
    "# The Inner Numbers must be the same\n",
    "# The 2 Tensors must be of the same data type\n",
    "\n",
    "print(tensor1.shape)\n",
    "\n",
    "tensor3 = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 7]\n",
    "])\n",
    "\n",
    "print(tensor3.shape)\n",
    "print(\"-\"*20)\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor3)\n",
    "\n",
    "print(f\"Tensor1 * Tensor3 = \")\n",
    "print(\"-\"*20)\n",
    "print(torch.mm(tensor1, tensor3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f46d60da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000, 1.5000],\n",
      "        [2.0000, 2.5000, 3.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Division Tensor ---->> with scalar\n",
    "print(tensor1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16617e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[-1,  2, -3],\n",
      "        [ 4, -5,  6]])\n",
      "----------------------\n",
      "Tensor1 / Tensor2 = \n",
      "tensor([[-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# 2. Tensor with another tensor ---->> Elementwise division\n",
    "print(tensor1)\n",
    "print(tensor2)\n",
    "print(\"-\"*22)\n",
    "print(\"Tensor1 / Tensor2 = \")\n",
    "print(tensor1/tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ff466",
   "metadata": {},
   "source": [
    "#### *`2.6. Broadcasting`*\n",
    "\n",
    "- a is a 1-dimensional tensor with shape ([ 3 ]).\n",
    "- b is a scalar tensor with shape ([ 1 ]).\n",
    "- When adding a and b, PyTorch broadcasts b to match the shape of a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0fd7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Broadcasting:\n",
      " tensor([5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "# Create two 1-dimensional tensors\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor(4)\n",
    "\n",
    "# adding a scalar to a vector\n",
    "result = a + b\n",
    "\n",
    "print(\"Result of Broadcasting:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066a8fb",
   "metadata": {},
   "source": [
    "- When adding a and b, PyTorch broadcasts b to match the shape of a, resulting in ([ 1 + 4, 2 + 4, 3 + 4 ]).\n",
    "\n",
    "- Broadcasting allows PyTorch to perform element-wise operations on tensors of\n",
    "\n",
    "- a is a 2-dimensional tensor with shape ([1, 3]).\n",
    "\n",
    "- b is a 2-dimensional tensor with shape ([3, 1]).\n",
    "\n",
    "- When adding a and b, PyTorch broadcasts both tensors to the common shape ([3, 3]), resulting in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "297ec623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3]])\n",
      "torch.Size([1, 3])\n",
      "tensor([[4],\n",
      "        [5],\n",
      "        [6]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors with shapes (1, 3) and (3, 1)\n",
    "a = torch.tensor([[1, 2, 3]])\n",
    "b = torch.tensor([[4], [5], [6]])\n",
    "\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa93a8",
   "metadata": {},
   "source": [
    "```[1, 2, 3]       [4][4][4]\n",
    "[1, 2, 3]   +   [5][5][5]\n",
    "[1, 2, 3]       [6][6][6]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27411f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 7],\n",
      "        [6, 7, 8],\n",
      "        [7, 8, 9]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "result = a + b\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22849b",
   "metadata": {},
   "source": [
    "#### *`2.7. CPU v/s GPU Tensor`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd2e750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89aaa6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  7 18:21:36 2026       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.69       Driver Version: 516.69       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M1000M      WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P8    N/A /  N/A |    181MiB /  2048MiB |     22%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     10864    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "|    0   N/A  N/A     11404    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     23352    C+G   ...ser\\Application\\brave.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1fd0965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fd97bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f700a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor for CPU -> This will occupy CPU RAM\n",
    "t_cpu = torch.tensor([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "], device='cpu')\n",
    "\n",
    "# Create a tensor for GPU -> This will occupy GPU RAM\n",
    "t_gpu = torch.tensor([\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2231136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses CPU RAM\n",
    "t_cpu = t_cpu * 5\n",
    "\n",
    "# This uses GPU RAM --->> Focus on GPU RAM Consumption\n",
    "t_gpu = t_gpu * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80f7a67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5., 10.],\n",
       "         [15., 20.],\n",
       "         [25., 30.]]),\n",
       " tensor([[ 5., 10.],\n",
       "         [15., 20.],\n",
       "         [25., 30.]], device='cuda:0'))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cpu, t_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00e14a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can move the GPU tensor to CPU and vice versa as shown below.\n",
    "\n",
    "# Move GPU tensor to CPU\n",
    "tensor_gpu_cpu = t_gpu.to(device='cpu')\n",
    "\n",
    "# Move CPU tensor to GPU\n",
    "tensor_cpu_gpu = t_cpu.to(device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
