{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95423f9d",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:30px;\">Image Classification Using Transfer Learning with Torchvision</h1>  \n",
    "\n",
    "In this notebook, we will learn how to train an Image Classifier on the **Caltech-256** dataset subset provided by using a pretrained model. We will use the **ResNet-50** network architecture but we instantiate the convolutional base of the network with weights that have been pre-trained on the ImageNet dataset.\n",
    "\n",
    "`We will add our own classification layer and only train the classifier part of the network. This technique is called transfer learning.`\n",
    "\n",
    "Finally we  will demonstrate that using a pre-trained convolutional base results in a tremendous jump in the performance metrics with literally no effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febbe5b0",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Overview of Pre-Trained Model Use Cases](#1.-Overview-of-Pre-Trained-Model-Use-Cases)\n",
    "* [2. Download and Extract the Caltech256 Subset Dataset](#2.-Download-and-Extract-the-Caltech256-Subset-Dataset)\n",
    "* [3. DataLoader Preparation](#3.-DataLoader-Preparation)\n",
    "* [4. Load the ResNet50 Pre-Trained Model](#4.-Load-the-ResNet50-Pre-Trained-Model)\n",
    "* [5. Model Training](#5.-Model-Training)\n",
    "* [6. Inference](#6.-Inference)\n",
    "* [7. Conclusion](#7.-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef259b0",
   "metadata": {},
   "source": [
    "## 1. Overview of Pre-Trained Model Use Cases\n",
    "\n",
    "A typical image classification architecture consists of 4 parts:-\n",
    "1.   Input image\n",
    "2.   Feature Extractor - a bank of convolutional layers that extract useful features for classification.\n",
    "3.   Classifier - a bank of fully connected layers that classify the image into its output classes.  \n",
    "4.   Output vector of class probabilities\n",
    "\n",
    "<img src=https://learnopencv.com/wp-content/uploads/2024/07/Transfer-learning.png align='center'><br/>\n",
    "\n",
    "Before we proceed with the coding implementation for Transfer Learning, it's helpful to review the table below, which summarizes several use cases.\n",
    "\n",
    "<img src=https://learnopencv.com/wp-content/uploads/2023/03/tensorflow-keras-training-methods.png width=850 align='center'><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1922e6a",
   "metadata": {},
   "source": [
    "### 1.1. Pre-Trained ImageNet Models\n",
    "\n",
    "- no training is required; you can simply load the model and make predictions on your pre-processed input images.\n",
    "- There are many pre-trained models available in Torchvision, which you can select from.\n",
    "- For situations where your application contains specific classes that are not contained in ImageNet we can perform finetuning by unfreezing several conv layers to adapt to new features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd3914",
   "metadata": {},
   "source": [
    "### 1.2. Train from Scratch\n",
    "- If you need to customize a model for a new dataset, one option is to load a model and train it from scratch.\n",
    "- When training from scratch, the entire model is initialized with random weights, and training is performed from scratch (with the predefined classifier).\n",
    "- Training a model from scratch requires a lot of data and a lot of computational resources, although this depends on the size of the model. Still, it's a significant factor to consider, especially if you don't have much data and acquiring labeled training data for your application is difficult.\n",
    "- Better options exist, but for reference, we trained the custom model from scratch in one of our previous post trained on 10 Monkey Species Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ce7dd",
   "metadata": {},
   "source": [
    "### 1.3. Transfer Learning\n",
    "\n",
    "- Simple approach for re-purposing a pre-trained model to make predictions on a new dataset.\n",
    "- The concept is simple. We use the model's pre-trained feature extractor (convolutional base) and re-train a new classifier to learn new weights for the new dataset.\n",
    "- This is sometimes referred to as \"`freezing`\" the layers in the feature extractor, meaning that we load the pre-trained weights and do not attempt to modify them further during the training process. \n",
    "- The theory is that the pre-trained ImageNet Feature Extractor has learned valuable features for detecting many different object types. \n",
    "- We assume such features are general enough that we only need to re-train the classifier portion of the network.\n",
    "\n",
    "- Requires much less data and computational resources than training from scratch.\n",
    "- Remember that training a model often takes many iterations to determine an appropriate set of hyper-parameters for a final model, so the time required to experiment and iterate will be significantly compounded. \n",
    "- Since pre-trained models were trained on millions of images, it behooves us to try and leverage that inherent capability. \n",
    "- Transfer learning allows you to quickly study how a pre-trained model can be customized for a new dataset. However, sometimes retraining the classifier isn't enough. This is where Fine-Tuning can be very beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e648de4",
   "metadata": {},
   "source": [
    "### 1.4. Fine Tuning\n",
    "\n",
    "- Fine-Tuning represents a flexible alternative to Transfer Learning. It is very similar to Transfer Learning. \n",
    "- Instead of locking down the feature extractor completely, we load the feature extractor with ImageNet weights and then `freeze the first several layers of the feature extractor but allow the last few layers to be trained further`. \n",
    "- The idea is that the first several layers in the feature extractor represent generic, low-level features (e.g., edges, corners, and arcs) that are fundamental building blocks necessary to support many classification tasks.\n",
    "- Subsequent layers in the feature extractor build upon the lower-level features to learn more complex representations that are more closely related to the content of a particular dataset.\n",
    "\n",
    "\n",
    "- With Fine-Tuning, we can specifically leverage the lower-level features of the pre-trained model but provide some flexibility for \"fine-tuning\" the last few layers of the convolutional base to provide the best possible customization for the dataset.\n",
    "- So we \"freeze\" the initial layers (i.e., make them non-trainable) and let the model train the last few layers of the feature extractor, as well as the classifier. \n",
    "- Note that all the layers in the feature extractor are initialized to ImageNet weights. Once training begins, the weights in the last few layers of the feature extractor are updated further, which is why this approach is called Fine-Tuning. Also, the weights in the classifier are initialized to small random values since we want the classifier to learn new weights required to classify new content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53edfe64",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a264eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchinfo -q\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f2420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # for deep learning computations\n",
    "import torchvision  # for pre-trained models and datasets\n",
    "import torch.nn as nn  # Import neural network module from PyTorch\n",
    "import torch.optim as optim  # Import optimizers for training models\n",
    "import time  # for measuring execution time\n",
    "import numpy as np  # for numerical operations\n",
    "import matplotlib.pyplot as plt  # for visualization\n",
    "import os  # for file system operations\n",
    "import zipfile  # for extracting compressed datasets\n",
    "import requests  # for downloading files\n",
    "\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "from PIL import Image  # for image processing\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchinfo import summary  # for displaying model summaries\n",
    "\n",
    "# for handling batch data loading\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set the Matplotlib style to 'ggplot' for better visuals\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ad1da",
   "metadata": {},
   "source": [
    "### 2. Download and Extract the Caltech256 Subset Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accc00da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Helper function to download file.\n",
    "def download_file(url, save_name):\n",
    "    url = url\n",
    "    if not os.path.exists(save_name):\n",
    "        file = requests.get(url)\n",
    "        open(save_name, 'wb').write(file.content)\n",
    "\n",
    "\n",
    "# Download the dataset.\n",
    "download_file(\n",
    "    'https://www.dropbox.com/s/0ltu2bsja3sb2j4/caltech256_subset.zip?dl=1',\n",
    "    'caltech256_subset.zip'\n",
    ")\n",
    "\n",
    "# Extract the dataset.\n",
    "file = 'caltech256_subset.zip'\n",
    "with zipfile.ZipFile(file, 'r') as zip:\n",
    "    # extract all files\n",
    "    print('extraction...')\n",
    "    zip.extractall()\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe9123",
   "metadata": {},
   "source": [
    "### 3. DataLoader Preparation\n",
    "\n",
    "The dataset we will be using here is a subset of Caltech256 dataset\n",
    " containing 10 categories and number of samples as follows:\n",
    " \n",
    "|     Class     | Train Samples | Valid Samples | Test Samples |\n",
    "|:-------------:|:-------------:|:-------------:|:------------:|\n",
    "|      bear     |       60      |       10      |      10      |\n",
    "|     chimp     |       60      |       10      |      10      |\n",
    "|    giraffe    |       60      |       10      |      10      |\n",
    "|    gorilla    |       60      |       10      |      10      |\n",
    "|     llama     |       60      |       10      |      10      |\n",
    "|    ostrich    |       60      |       10      |      10      |\n",
    "|   porcupine   |       60      |       10      |      10      |\n",
    "|     skunk     |       60      |       10      |      10      |\n",
    "| triceratops   |       60      |       10      |      10      |\n",
    "|     zebra     |       60      |       10      |      10      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c0d1d",
   "metadata": {},
   "source": [
    "### 3.1. Preprocessing Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a5e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining transformations to be applied to training, validation, and test datasets\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # Randomly crop the image with scaling\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        # Apply random rotation up to 15 degrees\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        # Flip the image horizontally with a probability of 0.5\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        # Crop the center of the image to 224x224 pixels\n",
    "        transforms.CenterCrop(size=224),\n",
    "        # Convert image to PyTorch tensor format\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize image using mean and standard deviation\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "\n",
    "    'valid': transforms.Compose([\n",
    "        # Resize the image to 256 pixels on the shorter side\n",
    "        transforms.Resize(size=256),\n",
    "        # Crop the center of the image to 224x224 pixels\n",
    "        transforms.CenterCrop(size=224),\n",
    "        # Convert image to PyTorch tensor format\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize image using mean and std\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "\n",
    "\n",
    "    'test': transforms.Compose([\n",
    "        # Resize the image to 256 pixels on the shorter side\n",
    "        transforms.Resize(size=256),\n",
    "        # Crop the center of the image to 224x224 pixels\n",
    "        transforms.CenterCrop(size=224),\n",
    "        # Convert image to PyTorch tensor format\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize image using mean and std\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ab6d6",
   "metadata": {},
   "source": [
    "### 3.2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cc5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Set the train, valid and test directory paths\n",
    "dataset = 'caltech256_subset'\n",
    "train_directory = os.path.join(dataset, 'train')\n",
    "valid_directory = os.path.join(dataset, 'valid')\n",
    "test_directory = os.path.join(dataset, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7d6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and number of classes\n",
    "batch_size = 32\n",
    "num_classes = len(os.listdir(valid_directory))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b490ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'bear', 1: 'chimp', 2: 'giraffe', 3: 'gorilla', 4: 'llama', 5: 'ostrich', 6: 'porcupine', 7: 'skunk', 8: 'triceratops', 9: 'zebra'}\n"
     ]
    }
   ],
   "source": [
    "# load data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid']),\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v:k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc94a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "test_data_size = len(data['test'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(data['test'], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d134167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used -> cpu\n",
      "Number of training samples:   600\n",
      "Number of validation samples: 100\n",
      "Number of test samples:       100\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device used -> {device}\")\n",
    "print(f\"Number of training samples:   {train_data_size}\")\n",
    "print(f\"Number of validation samples: {valid_data_size}\"),\n",
    "print(f\"Number of test samples:       {test_data_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ca448",
   "metadata": {},
   "source": [
    "### 4. Load the **ResNet50** Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc535fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights='DEFAULT')\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee546f0a",
   "metadata": {},
   "source": [
    "### 4.1. Set all the layers to be freezed initially\n",
    "\n",
    "By setting the `param.requires_grad = False` we ensure that all the model weights for those layers are freezed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae8a4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezq Model Parameters\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22edd301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4bec0",
   "metadata": {},
   "source": [
    "### 4.2. Unfreeze the final layer of the classifier's head\n",
    "\n",
    "As our dataset contains just 10 classes we have to modify the model's final layer from IMAGENET 1000 classes to match the num of classes of the subset dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080d1669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.4, inplace=False)\n",
       "  (3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (4): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the final fully connected layer of the ResNet50 model for transfer learning\n",
    "\n",
    "# 1. Get the number of input features for the final layer\n",
    "fc_inputs = resnet50.fc.in_features\n",
    "\n",
    "# 2. Define a new fully connected layer with custom architecture for classification\n",
    "resnet50.fc = nn.Sequential(\n",
    "    # Fully connected layer with 256 neurons\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    # Apply ReLU activation\n",
    "    nn.ReLU(),\n",
    "    # Apply dropout with 40% probability to prevent overfitting\n",
    "    nn.Dropout(0.4),\n",
    "    # Output layer with number of classes as output neurons\n",
    "    nn.Linear(256, num_classes),\n",
    "\n",
    "    # for multi-class classification (used with NLLLoss)\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device (either CUDA or CPU)\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "resnet50.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662cd4c",
   "metadata": {},
   "source": [
    "### 4.3. Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e400c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the loss function for classification\n",
    "loss_function = nn.NLLLoss()    # Suitable for Multi-class Classification\n",
    "\n",
    "# 2. Define the learning rate for the optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 3. Define the optimizer using Stochastic Gradient Descent (SGD)\n",
    "optimizer = optim.SGD(\n",
    "    params=resnet50.parameters(),   # Optimizing all parameters of the ResNet50 model\n",
    "    lr=learning_rate,\n",
    "    momentum=0.9    # to improve convergence and avoid local minima\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b9512",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "060b418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
    "    \"\"\"\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "\n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_loss = 100000.0\n",
    "    best_epoch = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        # 1. Set to training mode\n",
    "        model.train()\n",
    "\n",
    "        # 2. Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 1. Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 2. Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 3. Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            # 4. Backpropagate the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # 6. Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # 7. Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # 8. Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # 9. Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            print(\"Batch number: {:03d}, Training Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # 1. Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # 2. Validation loop\n",
    "            for j, (inputs, labels) in enumerate(valid_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 1. Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # 2. Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # 3. Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # 4. Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # 5. Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # 6. Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            # Save if the model has best accuracy till now\n",
    "            torch.save(model, 'best_model.pt')\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size\n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "\n",
    "        epoch_end = time.time()\n",
    "\n",
    "        print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Time: {:.4f}s\".format(\n",
    "            epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "\n",
    "    return model, history, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [32, 10]                  --\n",
      "├─Conv2d: 1-1                            [32, 64, 112, 112]        (9,408)\n",
      "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        (128)\n",
      "├─ReLU: 1-3                              [32, 64, 112, 112]        --\n",
      "├─MaxPool2d: 1-4                         [32, 64, 56, 56]          --\n",
      "├─Sequential: 1-5                        [32, 256, 56, 56]         --\n",
      "│    └─Bottleneck: 2-1                   [32, 256, 56, 56]         --\n",
      "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          (4,096)\n",
      "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          (128)\n",
      "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          --\n",
      "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          (36,864)\n",
      "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          (128)\n",
      "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          --\n",
      "│    │    └─Conv2d: 3-7                  [32, 256, 56, 56]         (16,384)\n",
      "│    │    └─BatchNorm2d: 3-8             [32, 256, 56, 56]         (512)\n",
      "│    │    └─Sequential: 3-9              [32, 256, 56, 56]         (16,896)\n",
      "│    │    └─ReLU: 3-10                   [32, 256, 56, 56]         --\n",
      "│    └─Bottleneck: 2-2                   [32, 256, 56, 56]         --\n",
      "│    │    └─Conv2d: 3-11                 [32, 64, 56, 56]          (16,384)\n",
      "│    │    └─BatchNorm2d: 3-12            [32, 64, 56, 56]          (128)\n",
      "│    │    └─ReLU: 3-13                   [32, 64, 56, 56]          --\n",
      "│    │    └─Conv2d: 3-14                 [32, 64, 56, 56]          (36,864)\n",
      "│    │    └─BatchNorm2d: 3-15            [32, 64, 56, 56]          (128)\n",
      "│    │    └─ReLU: 3-16                   [32, 64, 56, 56]          --\n",
      "│    │    └─Conv2d: 3-17                 [32, 256, 56, 56]         (16,384)\n",
      "│    │    └─BatchNorm2d: 3-18            [32, 256, 56, 56]         (512)\n",
      "│    │    └─ReLU: 3-19                   [32, 256, 56, 56]         --\n",
      "│    └─Bottleneck: 2-3                   [32, 256, 56, 56]         --\n",
      "│    │    └─Conv2d: 3-20                 [32, 64, 56, 56]          (16,384)\n",
      "│    │    └─BatchNorm2d: 3-21            [32, 64, 56, 56]          (128)\n",
      "│    │    └─ReLU: 3-22                   [32, 64, 56, 56]          --\n",
      "│    │    └─Conv2d: 3-23                 [32, 64, 56, 56]          (36,864)\n",
      "│    │    └─BatchNorm2d: 3-24            [32, 64, 56, 56]          (128)\n",
      "│    │    └─ReLU: 3-25                   [32, 64, 56, 56]          --\n",
      "│    │    └─Conv2d: 3-26                 [32, 256, 56, 56]         (16,384)\n",
      "│    │    └─BatchNorm2d: 3-27            [32, 256, 56, 56]         (512)\n",
      "│    │    └─ReLU: 3-28                   [32, 256, 56, 56]         --\n",
      "├─Sequential: 1-6                        [32, 512, 28, 28]         --\n",
      "│    └─Bottleneck: 2-4                   [32, 512, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-29                 [32, 128, 56, 56]         (32,768)\n",
      "│    │    └─BatchNorm2d: 3-30            [32, 128, 56, 56]         (256)\n",
      "│    │    └─ReLU: 3-31                   [32, 128, 56, 56]         --\n",
      "│    │    └─Conv2d: 3-32                 [32, 128, 28, 28]         (147,456)\n",
      "│    │    └─BatchNorm2d: 3-33            [32, 128, 28, 28]         (256)\n",
      "│    │    └─ReLU: 3-34                   [32, 128, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-35                 [32, 512, 28, 28]         (65,536)\n",
      "│    │    └─BatchNorm2d: 3-36            [32, 512, 28, 28]         (1,024)\n",
      "│    │    └─Sequential: 3-37             [32, 512, 28, 28]         (132,096)\n",
      "│    │    └─ReLU: 3-38                   [32, 512, 28, 28]         --\n",
      "│    └─Bottleneck: 2-5                   [32, 512, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-39                 [32, 128, 28, 28]         (65,536)\n",
      "│    │    └─BatchNorm2d: 3-40            [32, 128, 28, 28]         (256)\n",
      "│    │    └─ReLU: 3-41                   [32, 128, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-42                 [32, 128, 28, 28]         (147,456)\n",
      "│    │    └─BatchNorm2d: 3-43            [32, 128, 28, 28]         (256)\n",
      "│    │    └─ReLU: 3-44                   [32, 128, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-45                 [32, 512, 28, 28]         (65,536)\n",
      "│    │    └─BatchNorm2d: 3-46            [32, 512, 28, 28]         (1,024)\n",
      "│    │    └─ReLU: 3-47                   [32, 512, 28, 28]         --\n",
      "│    └─Bottleneck: 2-6                   [32, 512, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-48                 [32, 128, 28, 28]         (65,536)\n",
      "│    │    └─BatchNorm2d: 3-49            [32, 128, 28, 28]         (256)\n",
      "│    │    └─ReLU: 3-50                   [32, 128, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-51                 [32, 128, 28, 28]         (147,456)\n",
      "│    │    └─BatchNorm2d: 3-52            [32, 128, 28, 28]         (256)\n",
      "│    │    └─ReLU: 3-53                   [32, 128, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-54                 [32, 512, 28, 28]         (65,536)\n",
      "│    │    └─BatchNorm2d: 3-55            [32, 512, 28, 28]         (1,024)\n",
      "│    │    └─ReLU: 3-56                   [32, 512, 28, 28]         --\n",
      "│    └─Bottleneck: 2-7                   [32, 512, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-57                 [32, 128, 28, 28]         (65,536)\n",
      "│    │    └─BatchNorm2d: 3-58            [32, 128, 28, 28]         (256)\n",
      "│    │    └─ReLU: 3-59                   [32, 128, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-60                 [32, 128, 28, 28]         (147,456)\n",
      "│    │    └─BatchNorm2d: 3-61            [32, 128, 28, 28]         (256)\n",
      "│    │    └─ReLU: 3-62                   [32, 128, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-63                 [32, 512, 28, 28]         (65,536)\n",
      "│    │    └─BatchNorm2d: 3-64            [32, 512, 28, 28]         (1,024)\n",
      "│    │    └─ReLU: 3-65                   [32, 512, 28, 28]         --\n",
      "├─Sequential: 1-7                        [32, 1024, 14, 14]        --\n",
      "│    └─Bottleneck: 2-8                   [32, 1024, 14, 14]        --\n",
      "│    │    └─Conv2d: 3-66                 [32, 256, 28, 28]         (131,072)\n",
      "│    │    └─BatchNorm2d: 3-67            [32, 256, 28, 28]         (512)\n",
      "│    │    └─ReLU: 3-68                   [32, 256, 28, 28]         --\n",
      "│    │    └─Conv2d: 3-69                 [32, 256, 14, 14]         (589,824)\n",
      "│    │    └─BatchNorm2d: 3-70            [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-71                   [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-72                 [32, 1024, 14, 14]        (262,144)\n",
      "│    │    └─BatchNorm2d: 3-73            [32, 1024, 14, 14]        (2,048)\n",
      "│    │    └─Sequential: 3-74             [32, 1024, 14, 14]        (526,336)\n",
      "│    │    └─ReLU: 3-75                   [32, 1024, 14, 14]        --\n",
      "│    └─Bottleneck: 2-9                   [32, 1024, 14, 14]        --\n",
      "│    │    └─Conv2d: 3-76                 [32, 256, 14, 14]         (262,144)\n",
      "│    │    └─BatchNorm2d: 3-77            [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-78                   [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-79                 [32, 256, 14, 14]         (589,824)\n",
      "│    │    └─BatchNorm2d: 3-80            [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-81                   [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-82                 [32, 1024, 14, 14]        (262,144)\n",
      "│    │    └─BatchNorm2d: 3-83            [32, 1024, 14, 14]        (2,048)\n",
      "│    │    └─ReLU: 3-84                   [32, 1024, 14, 14]        --\n",
      "│    └─Bottleneck: 2-10                  [32, 1024, 14, 14]        --\n",
      "│    │    └─Conv2d: 3-85                 [32, 256, 14, 14]         (262,144)\n",
      "│    │    └─BatchNorm2d: 3-86            [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-87                   [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-88                 [32, 256, 14, 14]         (589,824)\n",
      "│    │    └─BatchNorm2d: 3-89            [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-90                   [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-91                 [32, 1024, 14, 14]        (262,144)\n",
      "│    │    └─BatchNorm2d: 3-92            [32, 1024, 14, 14]        (2,048)\n",
      "│    │    └─ReLU: 3-93                   [32, 1024, 14, 14]        --\n",
      "│    └─Bottleneck: 2-11                  [32, 1024, 14, 14]        --\n",
      "│    │    └─Conv2d: 3-94                 [32, 256, 14, 14]         (262,144)\n",
      "│    │    └─BatchNorm2d: 3-95            [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-96                   [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-97                 [32, 256, 14, 14]         (589,824)\n",
      "│    │    └─BatchNorm2d: 3-98            [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-99                   [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-100                [32, 1024, 14, 14]        (262,144)\n",
      "│    │    └─BatchNorm2d: 3-101           [32, 1024, 14, 14]        (2,048)\n",
      "│    │    └─ReLU: 3-102                  [32, 1024, 14, 14]        --\n",
      "│    └─Bottleneck: 2-12                  [32, 1024, 14, 14]        --\n",
      "│    │    └─Conv2d: 3-103                [32, 256, 14, 14]         (262,144)\n",
      "│    │    └─BatchNorm2d: 3-104           [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-105                  [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-106                [32, 256, 14, 14]         (589,824)\n",
      "│    │    └─BatchNorm2d: 3-107           [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-108                  [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-109                [32, 1024, 14, 14]        (262,144)\n",
      "│    │    └─BatchNorm2d: 3-110           [32, 1024, 14, 14]        (2,048)\n",
      "│    │    └─ReLU: 3-111                  [32, 1024, 14, 14]        --\n",
      "│    └─Bottleneck: 2-13                  [32, 1024, 14, 14]        --\n",
      "│    │    └─Conv2d: 3-112                [32, 256, 14, 14]         (262,144)\n",
      "│    │    └─BatchNorm2d: 3-113           [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-114                  [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-115                [32, 256, 14, 14]         (589,824)\n",
      "│    │    └─BatchNorm2d: 3-116           [32, 256, 14, 14]         (512)\n",
      "│    │    └─ReLU: 3-117                  [32, 256, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-118                [32, 1024, 14, 14]        (262,144)\n",
      "│    │    └─BatchNorm2d: 3-119           [32, 1024, 14, 14]        (2,048)\n",
      "│    │    └─ReLU: 3-120                  [32, 1024, 14, 14]        --\n",
      "├─Sequential: 1-8                        [32, 2048, 7, 7]          --\n",
      "│    └─Bottleneck: 2-14                  [32, 2048, 7, 7]          --\n",
      "│    │    └─Conv2d: 3-121                [32, 512, 14, 14]         (524,288)\n",
      "│    │    └─BatchNorm2d: 3-122           [32, 512, 14, 14]         (1,024)\n",
      "│    │    └─ReLU: 3-123                  [32, 512, 14, 14]         --\n",
      "│    │    └─Conv2d: 3-124                [32, 512, 7, 7]           (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-125           [32, 512, 7, 7]           (1,024)\n",
      "│    │    └─ReLU: 3-126                  [32, 512, 7, 7]           --\n",
      "│    │    └─Conv2d: 3-127                [32, 2048, 7, 7]          (1,048,576)\n",
      "│    │    └─BatchNorm2d: 3-128           [32, 2048, 7, 7]          (4,096)\n",
      "│    │    └─Sequential: 3-129            [32, 2048, 7, 7]          (2,101,248)\n",
      "│    │    └─ReLU: 3-130                  [32, 2048, 7, 7]          --\n",
      "│    └─Bottleneck: 2-15                  [32, 2048, 7, 7]          --\n",
      "│    │    └─Conv2d: 3-131                [32, 512, 7, 7]           (1,048,576)\n",
      "│    │    └─BatchNorm2d: 3-132           [32, 512, 7, 7]           (1,024)\n",
      "│    │    └─ReLU: 3-133                  [32, 512, 7, 7]           --\n",
      "│    │    └─Conv2d: 3-134                [32, 512, 7, 7]           (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-135           [32, 512, 7, 7]           (1,024)\n",
      "│    │    └─ReLU: 3-136                  [32, 512, 7, 7]           --\n",
      "│    │    └─Conv2d: 3-137                [32, 2048, 7, 7]          (1,048,576)\n",
      "│    │    └─BatchNorm2d: 3-138           [32, 2048, 7, 7]          (4,096)\n",
      "│    │    └─ReLU: 3-139                  [32, 2048, 7, 7]          --\n",
      "│    └─Bottleneck: 2-16                  [32, 2048, 7, 7]          --\n",
      "│    │    └─Conv2d: 3-140                [32, 512, 7, 7]           (1,048,576)\n",
      "│    │    └─BatchNorm2d: 3-141           [32, 512, 7, 7]           (1,024)\n",
      "│    │    └─ReLU: 3-142                  [32, 512, 7, 7]           --\n",
      "│    │    └─Conv2d: 3-143                [32, 512, 7, 7]           (2,359,296)\n",
      "│    │    └─BatchNorm2d: 3-144           [32, 512, 7, 7]           (1,024)\n",
      "│    │    └─ReLU: 3-145                  [32, 512, 7, 7]           --\n",
      "│    │    └─Conv2d: 3-146                [32, 2048, 7, 7]          (1,048,576)\n",
      "│    │    └─BatchNorm2d: 3-147           [32, 2048, 7, 7]          (4,096)\n",
      "│    │    └─ReLU: 3-148                  [32, 2048, 7, 7]          --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [32, 2048, 1, 1]          --\n",
      "├─Sequential: 1-10                       [32, 10]                  --\n",
      "│    └─Linear: 2-17                      [32, 256]                 524,544\n",
      "│    └─ReLU: 2-18                        [32, 256]                 --\n",
      "│    └─Dropout: 2-19                     [32, 256]                 --\n",
      "│    └─Linear: 2-20                      [32, 10]                  2,570\n",
      "│    └─LogSoftmax: 2-21                  [32, 10]                  --\n",
      "==========================================================================================\n",
      "Total params: 24,035,146\n",
      "Trainable params: 527,114\n",
      "Non-trainable params: 23,508,032\n",
      "Total mult-adds (G): 130.81\n",
      "==========================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 5690.43\n",
      "Params size (MB): 96.14\n",
      "Estimated Total Size (MB): 5805.84\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print the model to be trained.\n",
    "print(summary(resnet50, input_size=(batch_size, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3587d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25\n",
      "Batch number: 000, Training Loss: 1.9826, Accuracy: 0.7812\n",
      "Batch number: 001, Training Loss: 1.9299, Accuracy: 0.8750\n",
      "Batch number: 002, Training Loss: 1.9421, Accuracy: 0.8125\n",
      "Batch number: 003, Training Loss: 1.8836, Accuracy: 0.9062\n",
      "Batch number: 004, Training Loss: 1.8548, Accuracy: 0.8750\n",
      "Batch number: 005, Training Loss: 1.8097, Accuracy: 0.9688\n",
      "Batch number: 006, Training Loss: 1.8117, Accuracy: 0.8438\n",
      "Batch number: 007, Training Loss: 1.7176, Accuracy: 0.7812\n",
      "Batch number: 008, Training Loss: 1.7488, Accuracy: 0.7812\n",
      "Batch number: 009, Training Loss: 1.6653, Accuracy: 0.8125\n",
      "Batch number: 010, Training Loss: 1.5489, Accuracy: 0.9375\n",
      "Batch number: 011, Training Loss: 1.6558, Accuracy: 0.8750\n",
      "Batch number: 012, Training Loss: 1.5335, Accuracy: 0.9062\n",
      "Batch number: 013, Training Loss: 1.3864, Accuracy: 0.9375\n",
      "Batch number: 014, Training Loss: 1.6180, Accuracy: 0.7188\n",
      "Batch number: 015, Training Loss: 1.3392, Accuracy: 0.9062\n",
      "Batch number: 016, Training Loss: 1.2848, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 1.3262, Accuracy: 0.8438\n",
      "Batch number: 018, Training Loss: 1.1995, Accuracy: 0.9167\n",
      "Validation Batch number: 000, Validation: Loss: 1.2417, Accuracy: 0.9375\n",
      "Validation Batch number: 001, Validation: Loss: 1.0907, Accuracy: 1.0000\n",
      "Validation Batch number: 002, Validation: Loss: 1.2476, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 1.3872, Accuracy: 0.7500\n",
      "Epoch : 000, Training: Loss - 1.6501, Accuracy - 86.6667%, \n",
      "\t\tValidation : Loss - 1.2011, Accuracy - 96.0000%, Time: 119.2814s\n",
      "Epoch: 2/25\n",
      "Batch number: 000, Training Loss: 1.2076, Accuracy: 0.8438\n",
      "Batch number: 001, Training Loss: 1.1408, Accuracy: 0.9688\n",
      "Batch number: 002, Training Loss: 1.0626, Accuracy: 0.8750\n",
      "Batch number: 003, Training Loss: 1.0363, Accuracy: 0.9375\n",
      "Batch number: 004, Training Loss: 1.0515, Accuracy: 0.8750\n",
      "Batch number: 005, Training Loss: 1.0209, Accuracy: 0.9375\n",
      "Batch number: 006, Training Loss: 0.9339, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.8919, Accuracy: 0.9062\n",
      "Batch number: 008, Training Loss: 0.7512, Accuracy: 0.9688\n",
      "Batch number: 009, Training Loss: 0.8787, Accuracy: 0.9062\n",
      "Batch number: 010, Training Loss: 0.7427, Accuracy: 0.9062\n",
      "Batch number: 011, Training Loss: 0.7629, Accuracy: 0.8750\n",
      "Batch number: 012, Training Loss: 0.7830, Accuracy: 0.8750\n",
      "Batch number: 013, Training Loss: 0.6695, Accuracy: 0.8750\n",
      "Batch number: 014, Training Loss: 0.5312, Accuracy: 0.9688\n",
      "Batch number: 015, Training Loss: 0.7352, Accuracy: 0.9375\n",
      "Batch number: 016, Training Loss: 0.6745, Accuracy: 0.8438\n",
      "Batch number: 017, Training Loss: 0.7497, Accuracy: 0.8125\n",
      "Batch number: 018, Training Loss: 0.7163, Accuracy: 0.8750\n",
      "Validation Batch number: 000, Validation: Loss: 0.5076, Accuracy: 0.9375\n",
      "Validation Batch number: 001, Validation: Loss: 0.5567, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.5213, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.4514, Accuracy: 1.0000\n",
      "Epoch : 001, Training: Loss - 0.8619, Accuracy - 90.3333%, \n",
      "\t\tValidation : Loss - 0.5254, Accuracy - 94.0000%, Time: 129.5402s\n",
      "Epoch: 3/25\n",
      "Batch number: 000, Training Loss: 0.4241, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.3804, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.4622, Accuracy: 0.9375\n",
      "Batch number: 003, Training Loss: 0.6556, Accuracy: 0.8438\n",
      "Batch number: 004, Training Loss: 0.4549, Accuracy: 0.9375\n",
      "Batch number: 005, Training Loss: 0.4895, Accuracy: 0.9688\n",
      "Batch number: 006, Training Loss: 0.5494, Accuracy: 0.9375\n",
      "Batch number: 007, Training Loss: 0.4383, Accuracy: 0.9375\n",
      "Batch number: 008, Training Loss: 0.4985, Accuracy: 0.9062\n",
      "Batch number: 009, Training Loss: 0.3419, Accuracy: 0.9062\n",
      "Batch number: 010, Training Loss: 0.3330, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.2791, Accuracy: 0.9688\n",
      "Batch number: 012, Training Loss: 0.3958, Accuracy: 0.9062\n",
      "Batch number: 013, Training Loss: 0.3513, Accuracy: 0.9688\n",
      "Batch number: 014, Training Loss: 0.4113, Accuracy: 0.9375\n",
      "Batch number: 015, Training Loss: 0.3999, Accuracy: 0.8750\n",
      "Batch number: 016, Training Loss: 0.3552, Accuracy: 0.9375\n",
      "Batch number: 017, Training Loss: 0.2684, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.2958, Accuracy: 0.9583\n",
      "Validation Batch number: 000, Validation: Loss: 0.2116, Accuracy: 1.0000\n",
      "Validation Batch number: 001, Validation: Loss: 0.5096, Accuracy: 0.8750\n",
      "Validation Batch number: 002, Validation: Loss: 0.2415, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.1877, Accuracy: 1.0000\n",
      "Epoch : 002, Training: Loss - 0.4112, Accuracy - 94.1667%, \n",
      "\t\tValidation : Loss - 0.3156, Accuracy - 96.0000%, Time: 138.4895s\n",
      "Epoch: 4/25\n",
      "Batch number: 000, Training Loss: 0.3825, Accuracy: 0.9062\n",
      "Batch number: 001, Training Loss: 0.2686, Accuracy: 0.9688\n",
      "Batch number: 002, Training Loss: 0.1884, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.2678, Accuracy: 0.9688\n",
      "Batch number: 004, Training Loss: 0.2901, Accuracy: 0.9062\n",
      "Batch number: 005, Training Loss: 0.2302, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.2682, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.2606, Accuracy: 0.9375\n",
      "Batch number: 008, Training Loss: 0.2557, Accuracy: 0.9375\n",
      "Batch number: 009, Training Loss: 0.2853, Accuracy: 0.9062\n",
      "Batch number: 010, Training Loss: 0.2467, Accuracy: 0.9375\n",
      "Batch number: 011, Training Loss: 0.1574, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.2027, Accuracy: 0.9375\n",
      "Batch number: 013, Training Loss: 0.2078, Accuracy: 0.9688\n",
      "Batch number: 014, Training Loss: 0.1215, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.2754, Accuracy: 0.9688\n",
      "Batch number: 016, Training Loss: 0.2334, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.3732, Accuracy: 0.8750\n",
      "Batch number: 018, Training Loss: 0.1990, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.2826, Accuracy: 0.9375\n",
      "Validation Batch number: 001, Validation: Loss: 0.2022, Accuracy: 0.9688\n",
      "Validation Batch number: 002, Validation: Loss: 0.2490, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.1005, Accuracy: 1.0000\n",
      "Epoch : 003, Training: Loss - 0.2488, Accuracy - 95.5000%, \n",
      "\t\tValidation : Loss - 0.2388, Accuracy - 96.0000%, Time: 148.9811s\n",
      "Epoch: 5/25\n",
      "Batch number: 000, Training Loss: 0.2706, Accuracy: 0.9375\n",
      "Batch number: 001, Training Loss: 0.2440, Accuracy: 0.9688\n",
      "Batch number: 002, Training Loss: 0.2137, Accuracy: 0.9375\n",
      "Batch number: 003, Training Loss: 0.1331, Accuracy: 0.9688\n",
      "Batch number: 004, Training Loss: 0.2588, Accuracy: 0.9688\n",
      "Batch number: 005, Training Loss: 0.2584, Accuracy: 0.9062\n",
      "Batch number: 006, Training Loss: 0.1903, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.1152, Accuracy: 0.9688\n",
      "Batch number: 008, Training Loss: 0.1668, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.2273, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.2571, Accuracy: 0.9375\n",
      "Batch number: 011, Training Loss: 0.1504, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0959, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.1874, Accuracy: 0.9375\n",
      "Batch number: 014, Training Loss: 0.1980, Accuracy: 0.9688\n",
      "Batch number: 015, Training Loss: 0.2503, Accuracy: 0.9375\n",
      "Batch number: 016, Training Loss: 0.2552, Accuracy: 0.9375\n",
      "Batch number: 017, Training Loss: 0.1122, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.2666, Accuracy: 0.9167\n",
      "Validation Batch number: 000, Validation: Loss: 0.0431, Accuracy: 1.0000\n",
      "Validation Batch number: 001, Validation: Loss: 0.3198, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.2576, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.1323, Accuracy: 1.0000\n",
      "Epoch : 004, Training: Loss - 0.2018, Accuracy - 96.1667%, \n",
      "\t\tValidation : Loss - 0.2039, Accuracy - 96.0000%, Time: 151.8058s\n",
      "Epoch: 6/25\n",
      "Batch number: 000, Training Loss: 0.1669, Accuracy: 0.9375\n",
      "Batch number: 001, Training Loss: 0.2391, Accuracy: 0.9688\n",
      "Batch number: 002, Training Loss: 0.1929, Accuracy: 0.9688\n",
      "Batch number: 003, Training Loss: 0.2675, Accuracy: 0.9375\n",
      "Batch number: 004, Training Loss: 0.1870, Accuracy: 0.9375\n",
      "Batch number: 005, Training Loss: 0.1180, Accuracy: 0.9688\n",
      "Batch number: 006, Training Loss: 0.2348, Accuracy: 0.9375\n",
      "Batch number: 007, Training Loss: 0.2327, Accuracy: 0.9375\n",
      "Batch number: 008, Training Loss: 0.1969, Accuracy: 0.9375\n",
      "Batch number: 009, Training Loss: 0.3683, Accuracy: 0.9375\n",
      "Batch number: 010, Training Loss: 0.2163, Accuracy: 0.9375\n",
      "Batch number: 011, Training Loss: 0.1411, Accuracy: 0.9688\n",
      "Batch number: 012, Training Loss: 0.0800, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.1730, Accuracy: 0.9375\n",
      "Batch number: 014, Training Loss: 0.0878, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.1564, Accuracy: 0.9688\n",
      "Batch number: 016, Training Loss: 0.1461, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0588, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.2876, Accuracy: 0.9167\n",
      "Validation Batch number: 000, Validation: Loss: 0.2443, Accuracy: 0.9375\n",
      "Validation Batch number: 001, Validation: Loss: 0.2589, Accuracy: 0.9375\n",
      "Validation Batch number: 002, Validation: Loss: 0.1254, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.2014, Accuracy: 1.0000\n",
      "Epoch : 005, Training: Loss - 0.1856, Accuracy - 95.8333%, \n",
      "\t\tValidation : Loss - 0.2092, Accuracy - 95.0000%, Time: 106.4603s\n",
      "Epoch: 7/25\n",
      "Batch number: 000, Training Loss: 0.1843, Accuracy: 0.9375\n",
      "Batch number: 001, Training Loss: 0.1131, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.1150, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.1082, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.2450, Accuracy: 0.9375\n",
      "Batch number: 005, Training Loss: 0.2020, Accuracy: 0.9375\n",
      "Batch number: 006, Training Loss: 0.0945, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.1001, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.1416, Accuracy: 0.9688\n",
      "Batch number: 009, Training Loss: 0.1528, Accuracy: 0.9688\n",
      "Batch number: 010, Training Loss: 0.2021, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.0525, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.1960, Accuracy: 0.9688\n",
      "Batch number: 013, Training Loss: 0.1249, Accuracy: 0.9688\n",
      "Batch number: 014, Training Loss: 0.0655, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.2375, Accuracy: 0.9688\n",
      "Batch number: 016, Training Loss: 0.1262, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.1138, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.1096, Accuracy: 0.9583\n",
      "Validation Batch number: 000, Validation: Loss: 0.4425, Accuracy: 0.8750\n",
      "Validation Batch number: 001, Validation: Loss: 0.0539, Accuracy: 1.0000\n",
      "Validation Batch number: 002, Validation: Loss: 0.0563, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.3723, Accuracy: 0.7500\n",
      "Epoch : 006, Training: Loss - 0.1417, Accuracy - 97.6667%, \n",
      "\t\tValidation : Loss - 0.1917, Accuracy - 95.0000%, Time: 118.4696s\n",
      "Epoch: 8/25\n",
      "Batch number: 000, Training Loss: 0.1650, Accuracy: 0.9375\n",
      "Batch number: 001, Training Loss: 0.1120, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0634, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0674, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.1578, Accuracy: 0.9688\n",
      "Batch number: 005, Training Loss: 0.0614, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.1838, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.0855, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0888, Accuracy: 0.9688\n",
      "Batch number: 009, Training Loss: 0.0852, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0992, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.2035, Accuracy: 0.9375\n",
      "Batch number: 012, Training Loss: 0.1504, Accuracy: 0.9375\n",
      "Batch number: 013, Training Loss: 0.0655, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.1958, Accuracy: 0.9062\n",
      "Batch number: 015, Training Loss: 0.0865, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0877, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0726, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.1266, Accuracy: 0.9583\n",
      "Validation Batch number: 000, Validation: Loss: 0.0589, Accuracy: 1.0000\n",
      "Validation Batch number: 001, Validation: Loss: 0.2722, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.1975, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.0184, Accuracy: 1.0000\n",
      "Epoch : 007, Training: Loss - 0.1134, Accuracy - 97.6667%, \n",
      "\t\tValidation : Loss - 0.1699, Accuracy - 96.0000%, Time: 112.9790s\n",
      "Epoch: 9/25\n",
      "Batch number: 000, Training Loss: 0.0870, Accuracy: 0.9688\n",
      "Batch number: 001, Training Loss: 0.1357, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0593, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0627, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.1332, Accuracy: 0.9375\n",
      "Batch number: 005, Training Loss: 0.0360, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.1017, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.1239, Accuracy: 0.9688\n",
      "Batch number: 008, Training Loss: 0.0734, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.1810, Accuracy: 0.9375\n",
      "Batch number: 010, Training Loss: 0.1194, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.1051, Accuracy: 0.9688\n",
      "Batch number: 012, Training Loss: 0.2149, Accuracy: 0.9375\n",
      "Batch number: 013, Training Loss: 0.1116, Accuracy: 0.9688\n",
      "Batch number: 014, Training Loss: 0.0802, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0999, Accuracy: 0.9688\n",
      "Batch number: 016, Training Loss: 0.0633, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0416, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.1562, Accuracy: 0.9583\n",
      "Validation Batch number: 000, Validation: Loss: 0.1638, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.1874, Accuracy: 0.9688\n",
      "Validation Batch number: 002, Validation: Loss: 0.1357, Accuracy: 0.9375\n",
      "Validation Batch number: 003, Validation: Loss: 0.2460, Accuracy: 1.0000\n",
      "Epoch : 008, Training: Loss - 0.1038, Accuracy - 97.6667%, \n",
      "\t\tValidation : Loss - 0.1656, Accuracy - 96.0000%, Time: 117.3662s\n",
      "Epoch: 10/25\n",
      "Batch number: 000, Training Loss: 0.0617, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0940, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.1053, Accuracy: 0.9688\n",
      "Batch number: 003, Training Loss: 0.0523, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.1176, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0799, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0410, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.0893, Accuracy: 0.9688\n",
      "Batch number: 008, Training Loss: 0.0644, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0595, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0169, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.1790, Accuracy: 0.9688\n",
      "Batch number: 012, Training Loss: 0.0827, Accuracy: 0.9688\n",
      "Batch number: 013, Training Loss: 0.1669, Accuracy: 0.9688\n",
      "Batch number: 014, Training Loss: 0.1433, Accuracy: 0.9375\n",
      "Batch number: 015, Training Loss: 0.0859, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0500, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0988, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.0763, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.1153, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.2849, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.0740, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.0279, Accuracy: 1.0000\n",
      "Epoch : 009, Training: Loss - 0.0878, Accuracy - 98.8333%, \n",
      "\t\tValidation : Loss - 0.1528, Accuracy - 96.0000%, Time: 126.2296s\n",
      "Epoch: 11/25\n",
      "Batch number: 000, Training Loss: 0.1051, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0502, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0553, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0878, Accuracy: 0.9688\n",
      "Batch number: 004, Training Loss: 0.0967, Accuracy: 0.9688\n",
      "Batch number: 005, Training Loss: 0.1022, Accuracy: 0.9375\n",
      "Batch number: 006, Training Loss: 0.0737, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.1412, Accuracy: 0.9688\n",
      "Batch number: 008, Training Loss: 0.2169, Accuracy: 0.9062\n",
      "Batch number: 009, Training Loss: 0.1121, Accuracy: 0.9688\n",
      "Batch number: 010, Training Loss: 0.0669, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0739, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0530, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0695, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0333, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.1385, Accuracy: 0.9688\n",
      "Batch number: 016, Training Loss: 0.0746, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.1661, Accuracy: 0.9688\n",
      "Batch number: 018, Training Loss: 0.0616, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.0427, Accuracy: 1.0000\n",
      "Validation Batch number: 001, Validation: Loss: 0.2978, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.1161, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.0070, Accuracy: 1.0000\n",
      "Epoch : 010, Training: Loss - 0.0940, Accuracy - 98.0000%, \n",
      "\t\tValidation : Loss - 0.1464, Accuracy - 96.0000%, Time: 153.7019s\n",
      "Epoch: 12/25\n",
      "Batch number: 000, Training Loss: 0.0871, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0926, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0512, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0693, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0863, Accuracy: 0.9688\n",
      "Batch number: 005, Training Loss: 0.0492, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.1408, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.1235, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.1391, Accuracy: 0.9688\n",
      "Batch number: 009, Training Loss: 0.0606, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.1109, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.1110, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0640, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0585, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0718, Accuracy: 0.9688\n",
      "Batch number: 015, Training Loss: 0.0386, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0826, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.1436, Accuracy: 0.9688\n",
      "Batch number: 018, Training Loss: 0.0572, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.1147, Accuracy: 0.9375\n",
      "Validation Batch number: 001, Validation: Loss: 0.1218, Accuracy: 0.9688\n",
      "Validation Batch number: 002, Validation: Loss: 0.1556, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.4524, Accuracy: 1.0000\n",
      "Epoch : 011, Training: Loss - 0.0866, Accuracy - 98.8333%, \n",
      "\t\tValidation : Loss - 0.1436, Accuracy - 96.0000%, Time: 123.2823s\n",
      "Epoch: 13/25\n",
      "Batch number: 000, Training Loss: 0.0480, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0300, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0259, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0447, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0473, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0420, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0403, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.0887, Accuracy: 0.9688\n",
      "Batch number: 008, Training Loss: 0.0549, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0278, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0300, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0610, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.1686, Accuracy: 0.9375\n",
      "Batch number: 013, Training Loss: 0.0629, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0767, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0419, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0961, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.0396, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.2354, Accuracy: 0.8750\n",
      "Validation Batch number: 000, Validation: Loss: 0.1442, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.2551, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.0877, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.0082, Accuracy: 1.0000\n",
      "Epoch : 012, Training: Loss - 0.0642, Accuracy - 98.8333%, \n",
      "\t\tValidation : Loss - 0.1561, Accuracy - 96.0000%, Time: 205.5362s\n",
      "Epoch: 14/25\n",
      "Batch number: 000, Training Loss: 0.0623, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0872, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0775, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0490, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0489, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0374, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0406, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.0598, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0255, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0465, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0788, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.0455, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0835, Accuracy: 0.9688\n",
      "Batch number: 013, Training Loss: 0.1544, Accuracy: 0.9375\n",
      "Batch number: 014, Training Loss: 0.0474, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.1344, Accuracy: 0.9375\n",
      "Batch number: 016, Training Loss: 0.0520, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.0741, Accuracy: 0.9688\n",
      "Batch number: 018, Training Loss: 0.0405, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.1581, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.0231, Accuracy: 1.0000\n",
      "Validation Batch number: 002, Validation: Loss: 0.2166, Accuracy: 0.9375\n",
      "Validation Batch number: 003, Validation: Loss: 0.2965, Accuracy: 0.7500\n",
      "Epoch : 013, Training: Loss - 0.0659, Accuracy - 98.6667%, \n",
      "\t\tValidation : Loss - 0.1392, Accuracy - 96.0000%, Time: 192.6374s\n",
      "Epoch: 15/25\n",
      "Batch number: 000, Training Loss: 0.0545, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0671, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0559, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0756, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0449, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0865, Accuracy: 0.9688\n",
      "Batch number: 006, Training Loss: 0.0607, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.0253, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.1197, Accuracy: 0.9688\n",
      "Batch number: 009, Training Loss: 0.0778, Accuracy: 0.9688\n",
      "Batch number: 010, Training Loss: 0.0508, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0464, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0587, Accuracy: 0.9688\n",
      "Batch number: 013, Training Loss: 0.0843, Accuracy: 0.9375\n",
      "Batch number: 014, Training Loss: 0.0339, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0372, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0454, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0631, Accuracy: 0.9688\n",
      "Batch number: 018, Training Loss: 0.0235, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.1929, Accuracy: 0.9375\n",
      "Validation Batch number: 001, Validation: Loss: 0.2005, Accuracy: 0.9375\n",
      "Validation Batch number: 002, Validation: Loss: 0.0275, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.0850, Accuracy: 1.0000\n",
      "Epoch : 014, Training: Loss - 0.0590, Accuracy - 98.6667%, \n",
      "\t\tValidation : Loss - 0.1381, Accuracy - 96.0000%, Time: 116.5796s\n",
      "Epoch: 16/25\n",
      "Batch number: 000, Training Loss: 0.0808, Accuracy: 0.9688\n",
      "Batch number: 001, Training Loss: 0.0504, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0733, Accuracy: 0.9688\n",
      "Batch number: 003, Training Loss: 0.1066, Accuracy: 0.9688\n",
      "Batch number: 004, Training Loss: 0.0821, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0111, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0705, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.0674, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.1073, Accuracy: 0.9688\n",
      "Batch number: 009, Training Loss: 0.0232, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0309, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0124, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0347, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0709, Accuracy: 0.9688\n",
      "Batch number: 014, Training Loss: 0.1098, Accuracy: 0.9688\n",
      "Batch number: 015, Training Loss: 0.0868, Accuracy: 0.9688\n",
      "Batch number: 016, Training Loss: 0.0167, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0636, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.0576, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.2174, Accuracy: 0.9375\n",
      "Validation Batch number: 001, Validation: Loss: 0.1444, Accuracy: 0.9688\n",
      "Validation Batch number: 002, Validation: Loss: 0.0883, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.0123, Accuracy: 1.0000\n",
      "Epoch : 015, Training: Loss - 0.0609, Accuracy - 98.6667%, \n",
      "\t\tValidation : Loss - 0.1445, Accuracy - 96.0000%, Time: 114.2314s\n",
      "Epoch: 17/25\n",
      "Batch number: 000, Training Loss: 0.0749, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0324, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.1608, Accuracy: 0.9688\n",
      "Batch number: 003, Training Loss: 0.0557, Accuracy: 0.9688\n",
      "Batch number: 004, Training Loss: 0.0876, Accuracy: 0.9688\n",
      "Batch number: 005, Training Loss: 0.0761, Accuracy: 0.9688\n",
      "Batch number: 006, Training Loss: 0.0879, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.0531, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0318, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0292, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0153, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0782, Accuracy: 0.9688\n",
      "Batch number: 012, Training Loss: 0.0393, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0804, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0114, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0290, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0380, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0989, Accuracy: 0.9688\n",
      "Batch number: 018, Training Loss: 0.0509, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.3655, Accuracy: 0.8750\n",
      "Validation Batch number: 001, Validation: Loss: 0.0642, Accuracy: 0.9688\n",
      "Validation Batch number: 002, Validation: Loss: 0.0104, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.0272, Accuracy: 1.0000\n",
      "Epoch : 016, Training: Loss - 0.0596, Accuracy - 98.8333%, \n",
      "\t\tValidation : Loss - 0.1419, Accuracy - 95.0000%, Time: 106.9021s\n",
      "Epoch: 18/25\n",
      "Batch number: 000, Training Loss: 0.1107, Accuracy: 0.9688\n",
      "Batch number: 001, Training Loss: 0.0693, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0188, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.1069, Accuracy: 0.9688\n",
      "Batch number: 004, Training Loss: 0.0158, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0280, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0583, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.0232, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0590, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0781, Accuracy: 0.9688\n",
      "Batch number: 010, Training Loss: 0.0246, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0671, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0169, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0784, Accuracy: 0.9688\n",
      "Batch number: 014, Training Loss: 0.0327, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0300, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0476, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0177, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.0277, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.1730, Accuracy: 0.9062\n",
      "Validation Batch number: 001, Validation: Loss: 0.2094, Accuracy: 0.9375\n",
      "Validation Batch number: 002, Validation: Loss: 0.0465, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.0101, Accuracy: 1.0000\n",
      "Epoch : 017, Training: Loss - 0.0482, Accuracy - 99.1667%, \n",
      "\t\tValidation : Loss - 0.1376, Accuracy - 95.0000%, Time: 108.7221s\n",
      "Epoch: 19/25\n",
      "Batch number: 000, Training Loss: 0.0330, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0843, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0367, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0086, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0879, Accuracy: 0.9688\n",
      "Batch number: 005, Training Loss: 0.0776, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0272, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.0417, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0216, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0286, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0395, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0506, Accuracy: 0.9688\n",
      "Batch number: 012, Training Loss: 0.0569, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0396, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0108, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0202, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0857, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.0430, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.2517, Accuracy: 0.9167\n",
      "Validation Batch number: 000, Validation: Loss: 0.2021, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.1324, Accuracy: 0.9688\n",
      "Validation Batch number: 002, Validation: Loss: 0.1305, Accuracy: 0.9375\n",
      "Validation Batch number: 003, Validation: Loss: 0.0436, Accuracy: 1.0000\n",
      "Epoch : 018, Training: Loss - 0.0524, Accuracy - 99.1667%, \n",
      "\t\tValidation : Loss - 0.1505, Accuracy - 96.0000%, Time: 3130.8092s\n",
      "Epoch: 20/25\n",
      "Batch number: 000, Training Loss: 0.0248, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0727, Accuracy: 0.9375\n",
      "Batch number: 002, Training Loss: 0.0933, Accuracy: 0.9688\n",
      "Batch number: 003, Training Loss: 0.0584, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0233, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.1164, Accuracy: 0.9688\n",
      "Batch number: 006, Training Loss: 0.0418, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.0274, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0344, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0480, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0202, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0558, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.1112, Accuracy: 0.9375\n",
      "Batch number: 013, Training Loss: 0.0470, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0382, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0770, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0390, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0539, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.0744, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.0818, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.2719, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.1524, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.0042, Accuracy: 1.0000\n",
      "Epoch : 019, Training: Loss - 0.0554, Accuracy - 99.0000%, \n",
      "\t\tValidation : Loss - 0.1621, Accuracy - 95.0000%, Time: 117.0621s\n",
      "Epoch: 21/25\n",
      "Batch number: 000, Training Loss: 0.0756, Accuracy: 0.9688\n",
      "Batch number: 001, Training Loss: 0.0429, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0262, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0432, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0212, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0933, Accuracy: 0.9688\n",
      "Batch number: 006, Training Loss: 0.1202, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.0236, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0450, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.1377, Accuracy: 0.9688\n",
      "Batch number: 010, Training Loss: 0.1735, Accuracy: 0.9375\n",
      "Batch number: 011, Training Loss: 0.0191, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0584, Accuracy: 0.9688\n",
      "Batch number: 013, Training Loss: 0.0079, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0514, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0417, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0968, Accuracy: 0.9688\n",
      "Batch number: 017, Training Loss: 0.0533, Accuracy: 0.9688\n",
      "Batch number: 018, Training Loss: 0.0706, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.3218, Accuracy: 0.8750\n",
      "Validation Batch number: 001, Validation: Loss: 0.1340, Accuracy: 0.9688\n",
      "Validation Batch number: 002, Validation: Loss: 0.0199, Accuracy: 1.0000\n",
      "Validation Batch number: 003, Validation: Loss: 0.0056, Accuracy: 1.0000\n",
      "Epoch : 020, Training: Loss - 0.0632, Accuracy - 98.5000%, \n",
      "\t\tValidation : Loss - 0.1524, Accuracy - 95.0000%, Time: 132.9947s\n",
      "Epoch: 22/25\n",
      "Batch number: 000, Training Loss: 0.0278, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0304, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0271, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0417, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0147, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0436, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0353, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.0709, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.1125, Accuracy: 0.9375\n",
      "Batch number: 009, Training Loss: 0.1337, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0424, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.0326, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0198, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0422, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.1884, Accuracy: 0.9375\n",
      "Batch number: 015, Training Loss: 0.0471, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0195, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0506, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.0470, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.1340, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.2720, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.0622, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.0042, Accuracy: 1.0000\n",
      "Epoch : 021, Training: Loss - 0.0542, Accuracy - 99.1667%, \n",
      "\t\tValidation : Loss - 0.1500, Accuracy - 95.0000%, Time: 128.9716s\n",
      "Epoch: 23/25\n",
      "Batch number: 000, Training Loss: 0.0276, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0677, Accuracy: 0.9688\n",
      "Batch number: 002, Training Loss: 0.0234, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0798, Accuracy: 0.9688\n",
      "Batch number: 004, Training Loss: 0.0448, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0314, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0163, Accuracy: 1.0000\n",
      "Batch number: 007, Training Loss: 0.0091, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0387, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0175, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0605, Accuracy: 0.9688\n",
      "Batch number: 011, Training Loss: 0.0281, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0705, Accuracy: 0.9688\n",
      "Batch number: 013, Training Loss: 0.0263, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0278, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0234, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0235, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0118, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.1426, Accuracy: 0.9583\n",
      "Validation Batch number: 000, Validation: Loss: 0.0159, Accuracy: 1.0000\n",
      "Validation Batch number: 001, Validation: Loss: 0.3316, Accuracy: 0.8750\n",
      "Validation Batch number: 002, Validation: Loss: 0.1323, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.0314, Accuracy: 1.0000\n",
      "Epoch : 022, Training: Loss - 0.0392, Accuracy - 99.1667%, \n",
      "\t\tValidation : Loss - 0.1548, Accuracy - 95.0000%, Time: 164.5876s\n",
      "Epoch: 24/25\n",
      "Batch number: 000, Training Loss: 0.0251, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0717, Accuracy: 0.9688\n",
      "Batch number: 002, Training Loss: 0.0173, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0220, Accuracy: 1.0000\n",
      "Batch number: 004, Training Loss: 0.0267, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0432, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0866, Accuracy: 0.9375\n",
      "Batch number: 007, Training Loss: 0.0113, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0292, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0330, Accuracy: 1.0000\n",
      "Batch number: 010, Training Loss: 0.0480, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.0238, Accuracy: 1.0000\n",
      "Batch number: 012, Training Loss: 0.0139, Accuracy: 1.0000\n",
      "Batch number: 013, Training Loss: 0.0339, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0326, Accuracy: 0.9688\n",
      "Batch number: 015, Training Loss: 0.0322, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0428, Accuracy: 1.0000\n",
      "Batch number: 017, Training Loss: 0.0326, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.0443, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.0182, Accuracy: 1.0000\n",
      "Validation Batch number: 001, Validation: Loss: 0.2779, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.1286, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.4625, Accuracy: 0.7500\n",
      "Epoch : 023, Training: Loss - 0.0351, Accuracy - 99.3333%, \n",
      "\t\tValidation : Loss - 0.1544, Accuracy - 95.0000%, Time: 156.7567s\n",
      "Epoch: 25/25\n",
      "Batch number: 000, Training Loss: 0.0130, Accuracy: 1.0000\n",
      "Batch number: 001, Training Loss: 0.0186, Accuracy: 1.0000\n",
      "Batch number: 002, Training Loss: 0.0447, Accuracy: 1.0000\n",
      "Batch number: 003, Training Loss: 0.0960, Accuracy: 0.9375\n",
      "Batch number: 004, Training Loss: 0.0387, Accuracy: 1.0000\n",
      "Batch number: 005, Training Loss: 0.0154, Accuracy: 1.0000\n",
      "Batch number: 006, Training Loss: 0.0676, Accuracy: 0.9688\n",
      "Batch number: 007, Training Loss: 0.0225, Accuracy: 1.0000\n",
      "Batch number: 008, Training Loss: 0.0421, Accuracy: 1.0000\n",
      "Batch number: 009, Training Loss: 0.0571, Accuracy: 0.9688\n",
      "Batch number: 010, Training Loss: 0.0113, Accuracy: 1.0000\n",
      "Batch number: 011, Training Loss: 0.1041, Accuracy: 0.9688\n",
      "Batch number: 012, Training Loss: 0.0859, Accuracy: 0.9688\n",
      "Batch number: 013, Training Loss: 0.0363, Accuracy: 1.0000\n",
      "Batch number: 014, Training Loss: 0.0537, Accuracy: 1.0000\n",
      "Batch number: 015, Training Loss: 0.0219, Accuracy: 1.0000\n",
      "Batch number: 016, Training Loss: 0.0864, Accuracy: 0.9375\n",
      "Batch number: 017, Training Loss: 0.0292, Accuracy: 1.0000\n",
      "Batch number: 018, Training Loss: 0.0191, Accuracy: 1.0000\n",
      "Validation Batch number: 000, Validation: Loss: 0.0801, Accuracy: 0.9688\n",
      "Validation Batch number: 001, Validation: Loss: 0.2201, Accuracy: 0.9062\n",
      "Validation Batch number: 002, Validation: Loss: 0.1417, Accuracy: 0.9688\n",
      "Validation Batch number: 003, Validation: Loss: 0.0058, Accuracy: 1.0000\n",
      "Epoch : 024, Training: Loss - 0.0458, Accuracy - 98.6667%, \n",
      "\t\tValidation : Loss - 0.1416, Accuracy - 95.0000%, Time: 112.7700s\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "num_epochs = 25\n",
    "trained_model, history, best_epoch =train_and_validate(resnet50, loss_function, optimizer, num_epochs)\n",
    "\n",
    "# Save the History\n",
    "torch.save(history, dataset+'_history.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8c163",
   "metadata": {},
   "source": [
    "### 5.1. Plotting the Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eb9f3b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2D, but have shapes (1,) and (1, 2, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([history])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch Number\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mr\\anaconda3\\envs\\groq-agent\\lib\\site-packages\\matplotlib\\pyplot.py:3838\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3832\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3836\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3837\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3839\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3840\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3841\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3842\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3843\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mr\\anaconda3\\envs\\groq-agent\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\mr\\anaconda3\\envs\\groq-agent\\lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mr\\anaconda3\\envs\\groq-agent\\lib\\site-packages\\matplotlib\\axes\\_base.py:497\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    500\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[1;31mValueError\u001b[0m: x and y can be no greater than 2D, but have shapes (1,) and (1, 2, 4)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAAJMCAYAAAA1/w3JAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIl9JREFUeJzt3Q+s1XX9+PHXZfeyqIaIwCCZ/BGwP2P4p6yBFcjyT7EGiU6tWSOZOLfa+ms0Zy3Zwpzpoq01nYqFwiiKfyMLYRWw2X9Bp6joEvkjDIFVgCD3u/fnt3t/XLy3vJdzz5X7ejy2M/p8OJ97z729OZ7n+bw/79PQ3NzcHAAAAEn16ekHAAAA0JNEEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkFpjZw94+umnY/ny5fHiiy/Ga6+9Fl/72tfi4osv/q/HPPXUU7Fw4cJ4+eWX46yzzoqrrroqJk+efCqPGwAAoGfOFB05ciRGjhwZX/ziF9/S/V999dX4/ve/Hx/4wAfizjvvjE996lPxk5/8JP7+97935fECAAD07JmiCy64oLq9VY899lgMGTIkbrjhhmp7+PDh8cwzz8SqVavi/PPP7+y3BwAAOL2uKXruuedi/PjxbfZNmDAhtm7d2uExR48ejf/85z9tbmUfAABAj58p6qz9+/fHGWec0WZf2T506FC8/vrr0bdv3zcds2zZsli6dGnr9qRJk+LLX/5ydz9UAAAgoW6Poq6YMWNGTJs2rXW7oaGh+rMs7HDs2LEefGT0dmWsDRo0KPbu3RvNzc09/XDoxYw1jDV6G89r1EtjY2OceeaZtf2a0c0GDBgQBw4caLOvbPfr16/ds0RFU1NTdTtZCSLT6OhOLQFexpkowlijN/C8hrEGb4NrisaOHRubN29us+/JJ5+McePGdfe3BgAAqH0UHT58OF566aXq1rLkdvnfZbpRsWjRoliwYEHr/S+77LLqPj/72c/ilVdeid/85jexadOmamluAACAntbp6XMvvPBCfPe7323dLh/KWnz84x+PW265pbrupyWQirIc96233hoPPfRQrF69uvrw1jlz5liOGwAAeFtoaD6NLpzYs2ePa4ro9rn3w4YNi507d7qmCGONXsHzGsYavU1TU1MMHjz49LqmCAAA4O1MFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEitsSsHrVmzJlasWBH79++PESNGxKxZs2LMmDEd3n/VqlXx2GOPxd69e6N///7x4Q9/OK6//vro27fvqTx2AACA+p8p2rhxYyxcuDBmzpwZ8+fPr6Jo3rx5ceDAgXbv/8c//jEWLVoUV199dfzwhz+MOXPmxKZNm+KRRx459UcPAABQ7yhauXJlTJ06NaZMmRLDhw+P2bNnV2d81q1b1+79n3322TjvvPPikksuiSFDhsSECRNi0qRJ8fzzz5/qYwcAAKjv9Lljx47Ftm3bYvr06a37+vTpE+PHj4+tW7e2e0wJoj/84Q9VBJUpdrt3746//e1v8dGPfrTD73P06NHq1qKhoSH69etX/Vlu0F1axpdxRncz1qgXYw1jjd6moRt6oFNRdPDgwTh+/HgMGDCgzf6yvWPHjnaPKWeIynG33XZbtf3GG2/EJz7xifjMZz7T4fdZtmxZLF26tHV71KhR1VS9QYMGdebhQpcNHTrUb4+6MNaoF2MNYw1qvNBCZzz11FNV5Nx4440xduzY2LVrVzzwwANV9JTrktozY8aMmDZt2ptqsCzUcOIZJKi1MtbKC4cyTpubm/2C6TbGGvVirGGs0ds0NTXV/GRJp6KorBxXpsuVVedOVLZPPnvUYvHixfGxj32sug6pOOecc+Lw4cPx05/+tDpbVL5eez9ouZ2svEj1QpV6MNaoF2MNY43exvMa3a07eqBTCy00NjbG6NGjY8uWLa37ynS6sj1u3Lh2jzly5Mib5v21F0IAAACnxfS5Mq3txz/+cRVHZeGE1atXV+EzefLk6u8XLFgQAwcOrD6HqLjooouqzykq1wW1TJ8rZ4/KfnEEAACcdlE0ceLEauGEJUuWVNPmRo4cGXPnzm2dPleu+znxzNBVV11VbT/66KOxb9++agpeCaLrrruutj8JAABAFzQ0n0YX6ezZs8dCC3SrEvDDhg2LnTt3un4NY41ewfMaxhq9TVNTUwwePLimX9PFPQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqNXTlozZo1sWLFiti/f3+MGDEiZs2aFWPGjOnw/v/+97/jkUceiSeeeCL+9a9/xeDBg+Pzn/98XHjhhafy2AEAAOofRRs3boyFCxfG7NmzY+zYsbFq1aqYN29e3HPPPXHGGWe86f7Hjh2LO+64I/r37x9f+cpXYuDAgbF379545zvfeeqPHgAAoN5RtHLlypg6dWpMmTKl2i5x9Ne//jXWrVsX06dPf9P9H3/88ers0Pe+971obPx/327IkCGn+rgBAADqH0XlrM+2bdvaxE+fPn1i/PjxsXXr1naP+ctf/lKdUbr//vvjz3/+c3XGaNKkSdXXKMe25+jRo9WtRUNDQ/Tr16/6s9ygu7SML+OM7masUS/GGsYavU1DN/RAp6Lo4MGDcfz48RgwYECb/WV7x44d7R6ze/fu2LNnT1xyySXxrW99K3bt2hX33XdfvPHGG3H11Ve3e8yyZcti6dKlrdujRo2K+fPnx6BBgzrzcKHLhg4d6rdHXRhr1IuxhrEGNV5ooTOam5urs0M33XRTdWZo9OjRsW/fvli+fHmHUTRjxoyYNm3am2qwXIt04hkkqLUy1soLhxLvZexCdzHWqBdjDWON3qapqanmJ0s6FUUlbkrYlFXnTlS2Tz571KLsL9cSnThV7uyzz66OKdPxWq4zOvkHLbeTlRepXqhSD8Ya9WKsYazR23heo7t1Rw906nOKSsCUMz1btmxp3Vem05XtcePGtXvMeeedV73rXu7XYufOnXHmmWe2G0QAAABv6w9vLdPa1q5dG+vXr4/t27dX1wcdOXIkJk+eXP39ggULYtGiRa33v+yyy6rV5x588MHquqOyUl25Zujyyy+v7U8CAADQBZ0+VTNx4sRqwYUlS5ZUU+BGjhwZc+fObZ0+V677OXFFiDLf79vf/nY89NBD8fWvf736nKIrr7yy3eW7AQAA6q2h+TS6SKesYmehBbpTCfphw4ZVUzxPo38anIaMNYw1ehvPa9RLWXtg8ODBPTt9DgAAoDcRRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJCaKAIAAFITRQAAQGqiCAAASE0UAQAAqYkiAAAgNVEEAACkJooAAIDURBEAAJBaY1cOWrNmTaxYsSL2798fI0aMiFmzZsWYMWP+53EbNmyIe++9Nz74wQ/GN77xja58awAAgJ49U7Rx48ZYuHBhzJw5M+bPn19F0bx58+LAgQP/9bhXX301Hn744Xjf+953Ko8XAACgZ6No5cqVMXXq1JgyZUoMHz48Zs+eHX379o1169Z1eMzx48fjRz/6UVxzzTUxZMiQU33MAAAAPRNFx44di23btsX48eP//xfo06fa3rp1a4fHLV26NPr37x+XXnrpqT1aAACAnrym6ODBg9VZnwEDBrTZX7Z37NjR7jHPPPNMPP7443HnnXe+5e9z9OjR6taioaEh+vXrV/1ZbtBdWsaXcUZ3M9aoF2MNY43epqEbeqBLCy28VYcOHaqmzd10003VmaK3atmyZdXZpRajRo2qrl8aNGhQNz1SaGvo0KF+JdSFsUa9GGsYa1CjKCphU6bLlVXnTlS2Tz57VOzevTv27NlTBU2L5ubm6s9rr7027rnnnnafpGfMmBHTpk17Uw3u3bu3zRkkqLUy1sqY3LVrV+tYhe5grFEvxhrGGr1NU1NTzU+WdCqKGhsbY/To0bFly5a4+OKLq31lOl3ZvuKKK950//e85z1x1113tdn36KOPxuHDh+MLX/hChz9M+UHL7WTlRaoXqtSDsUa9GGsYa/Q2ntfobt3RA52ePlfO4Pz4xz+u4qh8NtHq1avjyJEjMXny5OrvFyxYEAMHDozrr7++WpXunHPOaXP8u971rurPk/cDAAD0hE5H0cSJE6sFF5YsWVJNmxs5cmTMnTu3dfpcmeLmInUAAOB00dB8Gs1HK9cnuaaI7lSCftiwYbFz505TNTHW6BU8r2Gs0ds0NTXF4MGDe/bDWwEAAHoTUQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACA1UQQAAKQmigAAgNREEQAAkJooAgAAUhNFAABAaqIIAABITRQBAACpiSIAACC1xq4ctGbNmlixYkXs378/RowYEbNmzYoxY8a0e9/f/e538fvf/z5efvnlanv06NFx3XXXdXh/AACAt/WZoo0bN8bChQtj5syZMX/+/CqK5s2bFwcOHGj3/k8//XRMmjQpbr/99rjjjjvirLPOqv7ct29fLR4/AABAfaNo5cqVMXXq1JgyZUoMHz48Zs+eHX379o1169a1e/8vfelLcfnll8fIkSPj7LPPjjlz5kRzc3Ns3rz51B45AABAvafPHTt2LLZt2xbTp09v3denT58YP358bN269S19jSNHjlRf593vfneH9zl69Gh1a9HQ0BD9+vWr/iw36C4t48s4o7sZa9SLsYaxRm/T0A090KkoOnjwYBw/fjwGDBjQZn/Z3rFjx1v6Gj//+c9j4MCBVUh1ZNmyZbF06dLW7VGjRlVT9QYNGtSZhwtdNnToUL896sJYo16MNYw1qPFCC131q1/9KjZs2BDf+c53qil3HZkxY0ZMmzbtTTW4d+/eNmeQoNbKWCsvHHbt2lVN84TuYqxRL8Yaxhq9TVNTU81PlnQqivr3719Nlyurzp2obJ989uhky5cvr6LotttuqxZn+F8/aLmdrLxI9UKVejDWqBdjDWON3sbzGt2tO3qgUwstNDY2Vktqb9mypXVfmU5XtseNG9fhcb/+9a/jF7/4RcydOzfOPffcU3vEAAAAPbn6XJnWtnbt2li/fn1s37497rvvvmrxhMmTJ1d/v2DBgli0aFHr/cvZocWLF8fNN98cQ4YMqc4qldvhw4dr+XMAAADU55qiiRMnVgsuLFmypIqbstR2OQPUMn2uXPdz4ooQv/3tb6vV5u6+++42X6d8ztE111zTtUcNAABQIw3Np9FFOnv27LHQAt2qBP2wYcNi586drl/DWKNX8LyGsUZv09TUFIMHD+7Z6XMAAAC9iSgCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQWmNXDlqzZk2sWLEi9u/fHyNGjIhZs2bFmDFjOrz/pk2bYvHixbFnz54YOnRofPazn40LL7zwVB43AABAz5wp2rhxYyxcuDBmzpwZ8+fPr6Jo3rx5ceDAgXbv/+yzz8a9994bl156aXX/D33oQ/GDH/wg/vnPf9bi8QMAANQ3ilauXBlTp06NKVOmxPDhw2P27NnRt2/fWLduXbv3X716dZx//vnx6U9/urr/tddeG6NHj67ONgEAAJxW0+eOHTsW27Zti+nTp7fu69OnT4wfPz62bt3a7jFl/7Rp09rsmzBhQvzpT3/q8PscPXq0urVoaGiIfv36RWNjl2b7wVtWxlrR1NQUzc3NfnN0G2ONejHWMNbobRq7oQk69RUPHjwYx48fjwEDBrTZX7Z37NjR7jHluqMzzjijzb6yXfZ3ZNmyZbF06dLW7UmTJsWXv/zlOPPMMzvzcKHLBg0a5LdHXRhr1IuxhrFGb3P06NHqjexeu/rcjBkz4sEHH2y9fe5zn6uuSzp06FBPPzR6uTLGvvnNbxprGGv0Gp7XMNbojc9r9957b5uZZXWNov79+1fT5U4+y1O2Tz571KLsP3kRhrLd0f2LUnzvfOc7W29l6tyGDRtMZ6LblSlzL774orGGsUav4XkNY43e+Ly2YcOGmn7NPp2dv1cWSdiyZUvrvjKdrmyPGzeu3WPK/s2bN7fZ9+STT8bYsWO7+pgBAABqptPT58qiCWvXro3169fH9u3b47777osjR47E5MmTq79fsGBBLFq0qPX+n/zkJ+Mf//hH9blGr7zySixZsiReeOGFuOKKK2r3UwAAAHRRp5dumDhxYrXgQombMm1u5MiRMXfu3NbpcHv37m1d6aY477zz4ktf+lI8+uij8cgjj8SwYcPi61//epxzzjlv+XuW6XTlc5FqdSEVGGv0NM9rGGv0Np7XOJ3HWkOzdYcBAIDE3parzwEAANSLKAIAAFITRQAAQGqiCAAASK3Tq891lzVr1lTLdpcV7UaMGBGzZs2KMWPGdHj/TZs2xeLFi2PPnj0xdOjQ+OxnPxsXXnhhXR8zp6fOjLXf/e538fvf/z5efvnlart8Ttd11133X8cmdGWsnah8IF35pO4PfvCD8Y1vfMMvlJo+rxX//ve/qxVhn3jiifjXv/4VgwcPjs9//vP+O0rNx9qqVaviscceq1Yn7t+/f3z4wx+O66+/Pvr27eu3TbuefvrpWL58ebz44ovx2muvxde+9rW4+OKL47956qmnYuHChdXrtbPOOiuuuuqq1o8LOq3OFG3cuLH6QcrSevPnz6/+kc2bNy8OHDjQ7v2fffbZ6gXDpZdeWt3/Qx/6UPzgBz+If/7zn3V/7JxeOjvWyj/MSZMmxe233x533HFH9Q+t/Llv3766P3Z691hr8eqrr8bDDz8c73vf++r2WMk11o4dO1Y9j5U3Fb/yla/EPffcEzfddFMMHDiw7o+d3j3W/vjHP1afXXn11VfHD3/4w5gzZ071pnYJcuhI+fzT8pE/X/ziF+OtKP/d/P73vx8f+MAH4s4774xPfepT8ZOf/CT+/ve/x2kXRStXroypU6fGlClTYvjw4TF79uzqHYR169a1e//Vq1fH+eefH5/+9Ker+1977bXVO/jl3Quo5Vgrn7F1+eWXV/84zz777OoJvaxiv3nzZr9oajrWiuPHj8ePfvSjuOaaa2LIkCF+w3TLWHv88cers0PlMwPf+973VmPt/e9/f/U8B7Uca+VN7PJ5lZdcckk1ziZMmFC90fj888/7RdOhCy64oHpt/7/ODrUoZyLL+LrhhhuqcXnFFVfERz7ykeos5WkVReUdq23btsX48eNb9/Xp06fa3rp1a7vHlP0n3r8o/9Cee+65bn+8nL66Mtbae/eifJ13v/vd3fhIyTrWli5dWk0vKWfBobvG2l/+8pcYO3Zs3H///dWL2q9+9avxy1/+sopyqOVYK0FUjmmJoN27d8ff/va36kUv1Ep5/d9eF7zV13Zvm2uKDh48WD0RDxgwoM3+sr1jx452jynzWM8444w2+8p22Q+1HGsn+/nPf15NMTn5Hx+c6lh75plnqnfwy6l/6M6xVl6Ylqlz5d37b33rW7Fr166477774o033qimOUGtxloZY+W42267rdouY+wTn/hEfOYzn/FLpmY66oJDhw7F66+//pavX+vxKILTxa9+9avqAvjvfOc7LhClpsoTd5k2V67rKGeKoDuVKcBlnJXxVt7pL9PPy3WS5cJmUUQtlYvfly1bFjfeeGN1drIE+AMPPFCdFS/XJcHbSY9HUXliLk/KJ5/lKdsnvxvRouw/+aK+st3R/aGrY61FebFQoqi821UuLIVajrWWd+7LhcsnvnAtyrzqciF8WWUTTnWsFWV/Y2NjdVyLcs1kOaZMkSp/B7UYa2WV4I997GPVdUjFOeecE4cPH46f/vSn1dmiE8cgdFVHXdCvX79OvYnd46OxPPmWd6m2bNnSuq+cni3b48aNa/eYsv/kC92ffPLJ6l0IqOVYK37961/HL37xi5g7d26ce+65fsHU/HntPe95T9x1113V1LmW20UXXdS6ks6gQYP81qnZ81q5zqO8Y3/iNUQ7d+6MM888UxBRs+e1lutwGxoa2uwTQtRaef3fXhf8t9d2b8soKqZNmxZr166N9evXx/bt26u5zeUfUsv64gsWLKiWdGzxyU9+Mv7xj39U6+S/8sorsWTJknjhhReq1SaglmOtnB0q73TdfPPN1com5R2xcivvdEGtxlp5J6u8g3ri7V3vele84x3vqP63d+6p5fPaZZddVq0+9+CDD1bXgvz1r3+tpjiVlTahlmOtvLnz29/+tpp6XpZNLi9Uy39Ty35xREfKa6yXXnqpuhVl7JT/XT7rqihjrIy1E5/Tyn1+9rOfVV3wm9/8plr6vSzN3Rlvi3PkEydOrC7EK3FTXnCWZUHLu/Itp2PLL+HEdxrKu1xlqeRHH320Wut+2LBh1dKi5cUD1HKslSfzMp3k7rvvbvN1ylzosmwy1GqsQb3GWjnz+O1vfzseeuih6r+dZfGYK6+8MqZPn+7/BGo61soHaJbt8nqtXLdWpuCVICofgg4dKSc6vvvd77Zul8/GKj7+8Y/HLbfcUn2ga0sgFeVN61tvvbV6Tisf21M+U7J8hEr5+J7OaGhumbgOAACQ0Nti+hwAAEBPEUUAAEBqoggAAEhNFAEAAKmJIgAAIDVRBAAApCaKAACA1EQRAACQmigCAABSE0UAAEBqoggAAEhNFAEAAJHZ/wGJzYUvPpp0jgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array([history])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(history[:, 0:2])\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(history[:, 0:2])\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18280c",
   "metadata": {},
   "source": [
    "Let's define a custom evaluation function that calculates the accuracy metric of our trained model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTestSetAccuracy(model, loss_criterion):\n",
    "    \"\"\"\n",
    "    Computes the accuracy and loss of the model on the test dataset.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The trained model to evaluate.\n",
    "    loss_criterion (torch.nn.Module): The loss function used for evaluation.\n",
    "\n",
    "    The function runs inference on the test dataset without tracking gradients,\n",
    "    calculates the loss and accuracy for each batch, and returns the average loss and accuracy.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    # Validation - No gradient tracking needed\n",
    "    with torch.no_grad():\n",
    "        # 1. Set to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # 2. Testing loop\n",
    "        for j, (inputs, labels) in enumerate(test_data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 1. Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # 2. Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            # 3. Compute the total loss for the batch and add it to test_loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # 4. Calculate test accuracy\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # 5. Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # 6. Compute total accuracy in the whole batch and add to test_acc\n",
    "            test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            print(f\"Test Batch number: {j:03d}, Test: Loss: {loss.item():.4f}, Accuracy: {acc.item():.4f}\")\n",
    "\n",
    "    # Find average test loss and test accuracy\n",
    "    avg_test_loss = test_loss / test_data_size\n",
    "    avg_test_acc = test_acc / test_data_size\n",
    "\n",
    "    print(\"Test accuracy: {:.4f}\".format(avg_test_acc))\n",
    "    print(\"Test loss: {:.4f}\".format(avg_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45193e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best saved model during training.\n",
    "model = torch.load(\"best_model.pt\".format(dataset, best_epoch), weights_only=False)\n",
    "\n",
    "# Evaluate the model's performance on the test dataset and print the results.\n",
    "computeTestSetAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1b169",
   "metadata": {},
   "source": [
    "### 6. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_image_name):\n",
    "    \"\"\"\n",
    "    Predicts the class of a given test image using a trained model.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The trained model to use for prediction.\n",
    "    test_image_name (str): The file path of the test image.\n",
    "\n",
    "    The function loads the image, applies necessary transformations, and\n",
    "    passes it through the model to get the top 3 predictions with their confidence scores.\n",
    "    \"\"\"\n",
    "    # 1. Applies the predefined transformation pipeline for test images\n",
    "    transform = image_transforms['test']\n",
    "    test_image = Image.open(test_image_name)\n",
    "\n",
    "    # 2. Creates a figure to visualize the test image\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    # 3. Displays the test image before applying transformations\n",
    "    plt.imshow(test_image)\n",
    "    plt.axis('off')  # Removes the axis for a cleaner image visualization\n",
    "\n",
    "    # 4. Apply transformations and reshape to fit model input\n",
    "    test_image_tensor = transform(test_image)\n",
    "    test_image_tensor = test_image_tensor.view(\n",
    "        1, 3, 224, 224)  # Reshape for batch processing\n",
    "\n",
    "    # 5. Checks if a GPU is available and moves the tensor to CUDA if possible\n",
    "    if torch.cuda.is_available():\n",
    "        test_image_tensor = test_image_tensor.cuda()\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient computation to optimize inference performance\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        out = model(test_image_tensor)  # Get model predictions\n",
    "        # Convert log probabilities to actual probabilities\n",
    "        ps = torch.exp(out)\n",
    "\n",
    "        # Extract the top 3 predictions and their probabilities\n",
    "        topk, topclass = ps.topk(3, dim=1)\n",
    "        # Get the top predicted class\n",
    "        cls = idx_to_class[topclass.cpu().numpy()[0][0]]\n",
    "        # Get the top prediction confidence score\n",
    "        score = topk.cpu().numpy()[0][0]\n",
    "\n",
    "        # Print the top 3 predictions with their confidence scores\n",
    "        for i in range(3):\n",
    "            print(f\"Prediction {i+1}: {idx_to_class[topclass.cpu().numpy()[0][i]]}\",f\"Score: {topk.cpu().numpy()[0][i]*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "urls = [\n",
    "    \"https://learnopencv.com/wp-content/uploads/2022/10/skunk.jpg\",\n",
    "    \"https://learnopencv.com/wp-content/uploads/2024/02/Zebra.jpg\",\n",
    "    \"https://learnopencv.com/wp-content/uploads/2024/07/llama-scaled.jpg\",\n",
    "    \"https://learnopencv.com/wp-content/uploads/2024/07/llama_-scaled.jpg\"\n",
    "]\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url, timeout=10)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        filename = os.path.basename(urlparse(url).path)\n",
    "        with open(f\"images/{filename}\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded: {filename} ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, 'skunk.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, 'Zebra.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, 'llama.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9022ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, 'llama_.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4e0c0",
   "metadata": {},
   "source": [
    "- `Fine-tuning pre-trained models` is a powerful technique that allows you to `re-purpose a model for a custom dataset`.\n",
    "\n",
    "- Torchvision comes bundled with many pre-trained classification models, allowing you to conveniently load a model in memory and configure it for Fine-Tuning. Let's summarize the key steps required for fine-tuning a pre-trained model.\n",
    "\n",
    "- When fine-tuning pre-trained models, we only load the convolutional base of the model, which is initialized with ImageNet weights.  \n",
    "- We \"freeze\" the first few layers of the convolutional base but allow the last few layers to be trained (\"fine-tuned\").\n",
    "- These steps are accomplished with the `param.requires_grad` to toggle which layers are trainable and which are not\n",
    "-. The number of layers to fine-tune is something you need to experiment with. \n",
    "- The classifier needs to be redefined based on the dataset and is initialized with random weights. \n",
    "- In this way, the model's initial state is in a favorable position for continued learning that allows it to adapt to a new dataset and learn faster (and potentially better) than training a model from scratch. \n",
    "- This approach also allows the model to be re-purposed for a new dataset with much less data than would be required for training a model from scratch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groq-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
